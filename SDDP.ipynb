{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d17a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gurobipy import Model, GRB, quicksum\n",
    "\n",
    "from Input_generator import generate_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949237fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- User knobs / constants -------------------------\n",
    "\n",
    "GAMMA = 1.0\n",
    "MAX_ITERS = 30\n",
    "OUT_PREFIX = \"sddp_alg6_mb\"\n",
    "OUTPUT_DIR = \"results_sddp\"\n",
    "SEED_TRAIN = 0\n",
    "\n",
    "# Minibatch settings for training forward pass\n",
    "USE_MINIBATCH = True\n",
    "BATCH_SIZE = 200        # per-iteration number of training paths to use (<= N_train)\n",
    "\n",
    "# Optional logging knobs\n",
    "LOG_LAST_ITER_ONLY = True\n",
    "LOG_MAX_PATHS = 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e6926e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Stepsize schedule α_n (Robbins–Monro style)\n",
    "def alpha(n, alpha0=0.5, power=0.6):\n",
    "    return alpha0 / (n ** power)\n",
    "\n",
    "# ------------------------- Helpers ----------------------------------------\n",
    "\n",
    "def add_theta_constraints(m, l_next_vars, cuts_a, cuts_b):\n",
    "    theta = m.addVar(lb=-GRB.INFINITY, name=\"theta_next\")\n",
    "    if len(cuts_a) == 0:\n",
    "        m.addConstr(theta <= 0.0, name=\"theta_le_0\")\n",
    "    else:\n",
    "        for k, (a, b) in enumerate(zip(cuts_a, cuts_b)):\n",
    "            expr = quicksum(float(a[j]) * l_next_vars[j] for j in range(len(a))) + float(b)\n",
    "            m.addConstr(theta <= expr, name=f\"theta_cut_{k}\")\n",
    "    return theta\n",
    "\n",
    "def stage_forward_lp(\n",
    "    t, l_t, nu_t, rho_t, R, pi_min, pi_max, l_min, l_max, g,\n",
    "    cuts_next_a, cuts_next_b, silent=True,\n",
    "    soft_bounds=True, level_penalty=1e6\n",
    "):\n",
    "    \"\"\"\n",
    "    Solve one stage LP and DISPOSE the model immediately (context manager).\n",
    "    Returns: obj, pi_next (J,), l_next (J,), omega (J,), theta_val (scalar)\n",
    "    \"\"\"\n",
    "    J = l_t.size\n",
    "\n",
    "    # Context manager ensures model & env resources are freed right away.\n",
    "    with Model(f\"fwd_t{t}\") as m:\n",
    "        if silent:\n",
    "            m.Params.OutputFlag = 0\n",
    "        m.Params.Threads = 1           # keep memory/CPU stable\n",
    "        # m.Params.Presolve = 2        # optional speed\n",
    "        # m.Params.NumericFocus = 1    # optional robustness\n",
    "\n",
    "        # Decision vars\n",
    "        pi_next = m.addVars(J, lb=pi_min.tolist(), ub=pi_max.tolist(), name=\"pi_next\")\n",
    "        l_next  = m.addVars(J, lb=-GRB.INFINITY if soft_bounds else l_min.tolist(),\n",
    "                               ub= GRB.INFINITY if soft_bounds else l_max.tolist(),\n",
    "                               name=\"l_next\")\n",
    "\n",
    "        # Balance equalities\n",
    "        bal_con = []\n",
    "        for j in range(J):\n",
    "            expr = l_next[j] - (float(l_t[j]) + float(nu_t[j]))\n",
    "            expr -= quicksum(float(R[j, k]) * pi_next[k] for k in range(J))\n",
    "            bal_con.append(m.addConstr(expr == 0.0, name=f\"balance_{j}\"))\n",
    "\n",
    "        # Soft bound slacks + penalty\n",
    "        pen_term = 0.0\n",
    "        if soft_bounds:\n",
    "            s_low  = m.addVars(J, lb=0.0, name=\"s_low\")\n",
    "            s_high = m.addVars(J, lb=0.0, name=\"s_high\")\n",
    "            for j in range(J):\n",
    "                m.addConstr(l_min[j] - l_next[j] <= s_low[j],  name=f\"soft_min_{j}\")\n",
    "                m.addConstr(l_next[j] - l_max[j] <= s_high[j], name=f\"soft_max_{j}\")\n",
    "            pen_term = level_penalty * (quicksum(s_low[j] for j in range(J)) +\n",
    "                                        quicksum(s_high[j] for j in range(J)))\n",
    "\n",
    "        # Theta constraints\n",
    "        theta = add_theta_constraints(m, [l_next[j] for j in range(J)],\n",
    "                                      cuts_next_a, cuts_next_b)\n",
    "\n",
    "        # Objective\n",
    "        rev = quicksum(float(rho_t[j]) * float(g[j]) * pi_next[j] for j in range(J))\n",
    "        m.setObjective(rev + theta - pen_term, GRB.MAXIMIZE)\n",
    "\n",
    "        m.optimize()\n",
    "        if m.Status not in (GRB.OPTIMAL, GRB.SUBOPTIMAL):\n",
    "            raise RuntimeError(f\"Stage LP infeasible/unbounded at t={t} (status {m.Status})\")\n",
    "\n",
    "        pi_sol = np.array([pi_next[j].X for j in range(J)], dtype=float)\n",
    "        l_sol  = np.array([l_next[j].X  for j in range(J)], dtype=float)\n",
    "        omega  = np.array([c.Pi for c in bal_con], dtype=float)\n",
    "        theta_val = float(theta.X)\n",
    "\n",
    "        return float(m.ObjVal), pi_sol, l_sol, omega, theta_val\n",
    "\n",
    "def evaluate_policy_on_paths(\n",
    "    cuts_a, cuts_b, l0, prices, inflow, R, pi_min, pi_max, l_min, l_max, g,\n",
    "    gamma=1.0, soft_bounds=True, level_penalty=1e6\n",
    "):\n",
    "    N_paths, T, J = prices.shape\n",
    "    totals = np.zeros(N_paths)\n",
    "    first_theta = np.zeros(N_paths)\n",
    "    for m in range(N_paths):\n",
    "        l_curr = l0.copy()\n",
    "        path_profit = 0.0\n",
    "        got_first = False\n",
    "        for t in range(T):\n",
    "            nu_t  = inflow[m, t, :]\n",
    "            rho_t = prices[m, t, :]\n",
    "            obj, pi_next, l_next, omega, theta_val = stage_forward_lp(\n",
    "                t=t, l_t=l_curr, nu_t=nu_t, rho_t=rho_t, R=R,\n",
    "                pi_min=pi_min, pi_max=pi_max, l_min=l_min, l_max=l_max, g=g,\n",
    "                cuts_next_a=[cuts_a[t+1]], cuts_next_b=[cuts_b[t+1]],\n",
    "                silent=True, soft_bounds=soft_bounds, level_penalty=level_penalty\n",
    "            )\n",
    "            if not got_first:\n",
    "                first_theta[m] = theta_val\n",
    "                got_first = True\n",
    "            path_profit += (gamma ** t) * obj\n",
    "            l_curr = l_next\n",
    "        totals[m] = path_profit\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        \"path_id\": np.arange(N_paths, dtype=int),\n",
    "        \"total_profit\": totals,\n",
    "        \"first_hour_theta\": first_theta\n",
    "    })\n",
    "\n",
    "# ------------------------- Core runner ------------------------------------\n",
    "\n",
    "def run_sddp_and_export(\n",
    "    N,\n",
    "    max_iters=MAX_ITERS,\n",
    "    gamma=GAMMA,\n",
    "    seed_train=SEED_TRAIN,\n",
    "    out_prefix=OUT_PREFIX,\n",
    "):\n",
    "    t_start = time.time()\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "    # ------------------------ Generate N scenarios ------------------------\n",
    "    gen = generate_input(N)\n",
    "\n",
    "    if isinstance(gen, dict):\n",
    "        J      = int(gen[\"J\"]); T = int(gen[\"T\"])\n",
    "        l_max  = np.asarray(gen[\"l_max\"], dtype=float)\n",
    "        l_min  = np.asarray(gen[\"l_min\"], dtype=float)\n",
    "        l0     = np.asarray(gen[\"l0\"], dtype=float)\n",
    "        pi_max = np.asarray(gen[\"pi_max\"], dtype=float)\n",
    "        pi_min = np.asarray(gen[\"pi_min\"], dtype=float)\n",
    "        R      = np.asarray(gen[\"R\"], dtype=float)\n",
    "        g      = np.asarray(gen.get(\"alpha_energy\", np.ones(J)), dtype=float)\n",
    "        prices = np.asarray(gen[\"prices_t\"], dtype=float)       # (N, T) or (N, T, J)\n",
    "        inflow = np.asarray(gen[\"inflows_tj\"], dtype=float)     # (N, T, J)\n",
    "    else:\n",
    "        (J, T, l_max, l_min, l0, pi_max, pi_min,\n",
    "         price_samples, inflow_samples, nu0, rho0,\n",
    "         R, a_t0, b_t0, l_bar0, alpha_energy) = gen\n",
    "        J      = int(J); T = int(T)\n",
    "        l_max  = np.asarray(l_max, dtype=float)\n",
    "        l_min  = np.asarray(l_min, dtype=float)\n",
    "        l0     = np.asarray(l0, dtype=float)\n",
    "        pi_max = np.asarray(pi_max, dtype=float)\n",
    "        pi_min = np.asarray(pi_min, dtype=float)\n",
    "        R      = np.asarray(R, dtype=float)\n",
    "        g      = np.asarray(alpha_energy, dtype=float)\n",
    "        prices = np.asarray(price_samples, dtype=float)\n",
    "        inflow = np.asarray(inflow_samples, dtype=float)\n",
    "\n",
    "    # (optional) halve memory; safe with Gurobi\n",
    "    prices = prices.astype(np.float32, copy=False)\n",
    "    inflow = inflow.astype(np.float32, copy=False)\n",
    "    l_max  = l_max.astype(np.float32,  copy=False)\n",
    "    l_min  = l_min.astype(np.float32,  copy=False)\n",
    "    l0     = l0.astype(np.float32,     copy=False)\n",
    "    pi_max = pi_max.astype(np.float32, copy=False)\n",
    "    pi_min = pi_min.astype(np.float32, copy=False)\n",
    "    g      = g.astype(np.float32,      copy=False)\n",
    "    R      = R.astype(np.float32,      copy=False)\n",
    "\n",
    "    if prices.ndim == 2:\n",
    "        prices = np.repeat(prices[:, :, None], J, axis=2)\n",
    "\n",
    "    assert inflow.shape == (N, T, J)\n",
    "    assert prices.shape == (N, T, J)\n",
    "\n",
    "    # --- Split into train/test (80% / 20%) ---\n",
    "    N_total = N\n",
    "    N_train = int(0.8 * N_total)\n",
    "    N_test  = N_total - N_train\n",
    "\n",
    "    idx_all = np.arange(N_total)\n",
    "    rng_state = np.random.get_state()\n",
    "    np.random.seed(seed_train)\n",
    "    np.random.shuffle(idx_all)\n",
    "    np.random.set_state(rng_state)\n",
    "\n",
    "    idx_train = idx_all[:N_train]\n",
    "    idx_test  = idx_all[N_train:]\n",
    "\n",
    "    prices_train = prices[idx_train, :, :]\n",
    "    inflow_train = inflow[idx_train, :, :]\n",
    "    prices_test  = prices[idx_test, :, :]\n",
    "    inflow_test  = inflow[idx_test, :, :]\n",
    "\n",
    "    M = N_train\n",
    "\n",
    "    # Initialize current (single) cut per stage\n",
    "    cuts_a = [np.zeros(J, dtype=np.float32) for _ in range(T+1)]\n",
    "    cuts_b = [0.0 for _ in range(T+1)]\n",
    "\n",
    "    history = {\"iter\": [], \"avg_forward_value\": [], \"cum_abs_delta\": []}\n",
    "    perstage_rows = []\n",
    "    cum_abs = 0.0\n",
    "\n",
    "    # ------------------------ SDDP iterations ------------------------\n",
    "    for n in range(1, max_iters + 1):\n",
    "        an = alpha(n)\n",
    "\n",
    "        # ---- choose minibatch for this iteration ----\n",
    "        if USE_MINIBATCH and M > 0:\n",
    "            rng_state = np.random.get_state()\n",
    "            np.random.seed(SEED_TRAIN + n)  # different batch each iteration\n",
    "            batch_idx = np.random.choice(M, size=min(BATCH_SIZE, M), replace=False)\n",
    "            np.random.set_state(rng_state)\n",
    "        else:\n",
    "            batch_idx = np.arange(M)\n",
    "\n",
    "        B = len(batch_idx)\n",
    "\n",
    "        # Pre-allocate for backward updates (just for batch)\n",
    "        omega_tm = np.zeros((T, B, J), dtype=np.float32)\n",
    "        Vhat_tm  = np.zeros((T, B),    dtype=np.float32)\n",
    "        l_t_mat  = np.zeros((B, T, J), dtype=np.float32)\n",
    "\n",
    "        path_objs = np.zeros(B, dtype=np.float64)\n",
    "\n",
    "        for local_i, m_idx in enumerate(batch_idx):\n",
    "            l_curr = l0.copy()\n",
    "            for t in range(T):\n",
    "                nu_t  = inflow_train[m_idx, t, :]\n",
    "                rho_t = prices_train[m_idx, t, :]\n",
    "                l_t_mat[local_i, t, :] = l_curr\n",
    "\n",
    "                obj, pi_next, l_next, omega, theta_val = stage_forward_lp(\n",
    "                    t=t, l_t=l_curr, nu_t=nu_t, rho_t=rho_t, R=R,\n",
    "                    pi_min=pi_min, pi_max=pi_max, l_min=l_min, l_max=l_max, g=g,\n",
    "                    cuts_next_a=[cuts_a[t+1]], cuts_next_b=[cuts_b[t+1]],\n",
    "                    silent=True, soft_bounds=True, level_penalty=1e6\n",
    "                )\n",
    "\n",
    "                # Logging (last iter only, limited paths)\n",
    "                if (not LOG_LAST_ITER_ONLY) or (n == max_iters):\n",
    "                    if local_i < LOG_MAX_PATHS:\n",
    "                        row = {\n",
    "                            \"N\": N, \"iter\": n, \"path_id\": int(local_i), \"t\": int(t),\n",
    "                            \"obj\": float(obj), \"theta\": float(theta_val)\n",
    "                        }\n",
    "                        perstage_rows.append(row)\n",
    "\n",
    "                path_objs[local_i] += (gamma ** t) * obj\n",
    "                Vhat_tm[t, local_i] = obj\n",
    "                omega_tm[t, local_i, :] = omega.astype(np.float32, copy=False)\n",
    "                l_curr = l_next\n",
    "\n",
    "        avg_forward = float(np.mean(path_objs)) if B > 0 else 0.0\n",
    "        if n == 1:\n",
    "            cum_abs += 0.0\n",
    "        else:\n",
    "            prev = history[\"avg_forward_value\"][-1]\n",
    "            cum_abs += abs(avg_forward - prev)\n",
    "\n",
    "        history[\"iter\"].append(n)\n",
    "        history[\"avg_forward_value\"].append(avg_forward)\n",
    "        history[\"cum_abs_delta\"].append(cum_abs)\n",
    "\n",
    "        # ---- Backward updates using the batch averages ----\n",
    "        for t in reversed(range(T)):\n",
    "            if B == 0:\n",
    "                continue\n",
    "            omega_bar = np.mean(omega_tm[t, :, :], axis=0)  # (J,)\n",
    "            # adjust_bar = mean_m ( Vhat_t^m - omega_t^m^T * l_t^m )\n",
    "            adjust_bar = float(\n",
    "                np.mean(\n",
    "                    Vhat_tm[t, :] - np.sum(omega_tm[t, :, :] * l_t_mat[:, t, :], axis=1)\n",
    "                )\n",
    "            )\n",
    "\n",
    "            cuts_a[t] = (1.0 - an) * cuts_a[t] + an * omega_bar\n",
    "            cuts_b[t] = (1.0 - an) * cuts_b[t] + an * adjust_bar\n",
    "\n",
    "        print(f\"  Iter {n:02d}: avg forward value = {avg_forward:,.3f} (cumΔ={cum_abs:,.3f})\")\n",
    "\n",
    "    # ------------------------ Save training logs ------------------------\n",
    "    df_hist = pd.DataFrame(history)\n",
    "    df_hist[\"N\"] = N\n",
    "    df_hist.to_csv(os.path.join(OUTPUT_DIR, f\"{out_prefix}_history_N{N}.csv\"), index=False)\n",
    "\n",
    "    df_train_perstage = pd.DataFrame(perstage_rows)\n",
    "    df_train_perstage.to_csv(os.path.join(OUTPUT_DIR, f\"{out_prefix}_train_perstage_N{N}.csv\"), index=False)\n",
    "\n",
    "    # ------------------------ Train/Test evaluation with final cuts ------------------------\n",
    "    df_eval_train = evaluate_policy_on_paths(\n",
    "        cuts_a, cuts_b, l0, prices_train, inflow_train,\n",
    "        R, pi_min, pi_max, l_min, l_max, g,\n",
    "        gamma=GAMMA, soft_bounds=True, level_penalty=1e6\n",
    "    )\n",
    "    df_eval_train.to_csv(os.path.join(OUTPUT_DIR, f\"{out_prefix}_train_eval_perpath_N{N}.csv\"), index=False)\n",
    "\n",
    "    df_eval_test = evaluate_policy_on_paths(\n",
    "        cuts_a, cuts_b, l0, prices_test, inflow_test,\n",
    "        R, pi_min, pi_max, l_min, l_max, g,\n",
    "        gamma=GAMMA, soft_bounds=True, level_penalty=1e6\n",
    "    )\n",
    "    df_eval_test.to_csv(os.path.join(OUTPUT_DIR, f\"{out_prefix}_test_perpath_N{N}.csv\"), index=False)\n",
    "\n",
    "    # In-sample stats (on evaluation rollouts)\n",
    "    in_mean = float(df_eval_train[\"total_profit\"].mean()) if not df_eval_train.empty else 0.0\n",
    "    in_std  = float(df_eval_train[\"total_profit\"].std(ddof=1)) if len(df_eval_train) > 1 else 0.0\n",
    "    first_mean = float(df_eval_train[\"first_hour_theta\"].mean()) if not df_eval_train.empty else 0.0\n",
    "    first_std  = float(df_eval_train[\"first_hour_theta\"].std(ddof=1)) if len(df_eval_train) > 1 else 0.0\n",
    "\n",
    "    # Test stats\n",
    "    test_mean = float(df_eval_test[\"total_profit\"].mean()) if not df_eval_test.empty else 0.0\n",
    "    test_std  = float(df_eval_test[\"total_profit\"].std(ddof=1)) if len(df_eval_test) > 1 else 0.0\n",
    "\n",
    "    runtime_sec = time.time() - t_start\n",
    "\n",
    "    # Save final cuts per stage\n",
    "    rows = []\n",
    "    for t in range(T+1):\n",
    "        rows.append({\"stage\": t, **{f\"a_{j}\": float(cuts_a[t][j]) for j in range(J)}, \"b\": float(cuts_b[t]), \"N\": N})\n",
    "    pd.DataFrame(rows).to_csv(os.path.join(OUTPUT_DIR, f\"{out_prefix}_cuts_N{N}.csv\"), index=False)\n",
    "\n",
    "    # One-row summary\n",
    "    df_sum = pd.DataFrame([{\n",
    "        \"N\": N, \"train_size\": N_train, \"test_size\": N_test, \"iters\": max_iters,\n",
    "        \"runtime_sec\": runtime_sec,\n",
    "        \"final_avg_forward_value\": history[\"avg_forward_value\"][-1] if history[\"avg_forward_value\"] else 0.0,\n",
    "        \"cum_abs_delta\": history[\"cum_abs_delta\"][-1] if history[\"cum_abs_delta\"] else 0.0,\n",
    "        \"in_sample_mean\": in_mean, \"in_sample_std\": in_std,\n",
    "        \"test_mean\": test_mean, \"test_std\": test_std,\n",
    "        \"first_hour_theta_mean\": first_mean, \"first_hour_theta_std\": first_std\n",
    "    }])\n",
    "\n",
    "    return ({\"a\": cuts_a, \"b\": cuts_b}, {\"history\": df_hist}, df_sum)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a7fda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- Driver: loop over N ----------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "    all_summaries = []\n",
    "    N = None\n",
    "\n",
    "    if N is None:\n",
    "        for N in range(100, 1001, 100):  # 100, 200, ..., 2000\n",
    "            print(f\"\\n=== Running SDDP with N={N} samples ===\")\n",
    "            _, _, df_sum = run_sddp_and_export(\n",
    "                N=N, max_iters=MAX_ITERS, gamma=GAMMA,\n",
    "                seed_train=SEED_TRAIN, out_prefix=OUT_PREFIX\n",
    "            )\n",
    "            all_summaries.append(df_sum)\n",
    "    else:\n",
    "        print(f\"\\n=== Running SDDP with N={N} samples ===\")\n",
    "        _, _, df_sum = run_sddp_and_export(\n",
    "            N=N, max_iters=MAX_ITERS, gamma=GAMMA,\n",
    "            seed_train=SEED_TRAIN, out_prefix=OUT_PREFIX\n",
    "        )\n",
    "        all_summaries.append(df_sum)\n",
    "\n",
    "    df_all = pd.concat(all_summaries, ignore_index=True)\n",
    "    df_all.to_csv(os.path.join(OUTPUT_DIR, f\"{OUT_PREFIX}_summary_allN.csv\"), index=False)\n",
    "    print(\"\\nDone. Summaries written to\", os.path.abspath(OUTPUT_DIR))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
