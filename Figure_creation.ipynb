{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fbf534",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import re, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- CONFIG ---\n",
    "DIR_ADP   = Path(\"results_adp\")\n",
    "DIR_SDDP  = Path(\"results_sddp\")\n",
    "DIR_EEVWS = Path(\"results_eev_ws\")\n",
    "DIR_ADPUC  = Path(\"results_adp_unit\")\n",
    "DEBUG_SCAN = True\n",
    "\n",
    "COL_TIME   = [\"stage\", \"Stage\", \"t\", \"time\", \"hour\", \"k\", \"step\"]\n",
    "COL_SAMPLE = [\"path\", \"Path\", \"path_id\",\"sample\", \"id\", \"sample_id\", \"scenario\", \"seed\", \"traj\", \"trajectory\", \"run\"]\n",
    "COL_VALUE_INCREMENTAL = [\"obj_stage\", \"rev_stage\", \"reward_stage\", \"value_stage\", \"stage_value\", \"stage_reward\", \"stage_obj\"]\n",
    "COL_VALUE_CUMULATIVE  = [\"obj_total\", \"total_obj\", \"cum_value\",\"cum_abs_delta\", \"cum_profit\", \"cum_reward\", \"objective\", \"obj\", \"profit\", \"value\"]\n",
    "\n",
    "def _pick(df, cands): \n",
    "    for c in cands:\n",
    "        if c in df.columns: return c\n",
    "    return None\n",
    "\n",
    "def _coerce_time_inplace(df, col=\"t\"):\n",
    "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[col]).copy()\n",
    "    df[col] = df[col].astype(int)\n",
    "    return df\n",
    "\n",
    "# -------- discovery ----------\n",
    "_pat = \"*train_perstage*N*.csv\"\n",
    "_rxN = re.compile(r\"_N(\\d+)\\.csv$\", re.IGNORECASE)\n",
    "\n",
    "def discover_perstage_files(root: Path) -> Dict[int, Path]:\n",
    "    \"\"\"\n",
    "    Return {N: filepath} for any '*train_perstage*N*.csv' found in root.\n",
    "    If multiple files match same N, keep the first (or choose the longest name deterministically).\n",
    "    \"\"\"\n",
    "    mapping: Dict[int, Path] = {}\n",
    "    hits = sorted(Path(root).glob(_pat))\n",
    "    if DEBUG_SCAN:\n",
    "        print(f\"[SCAN] {root}/'{_pat}' -> {len(hits)} files\")\n",
    "    for f in hits:\n",
    "        m = _rxN.search(f.name)\n",
    "        if not m: \n",
    "            continue\n",
    "        N = int(m.group(1))\n",
    "        if N not in mapping:\n",
    "            mapping[N] = f\n",
    "        if DEBUG_SCAN:\n",
    "            try:\n",
    "                cols = list(pd.read_csv(f, nrows=1).columns)\n",
    "            except Exception as e:\n",
    "                cols = [f\"ERROR: {e}\"]\n",
    "            print(f\"       N={N:>4} -> {f.name}  cols[:10]={cols[:10]}\")\n",
    "    return dict(sorted(mapping.items()))\n",
    "\n",
    "# -------- readers ----------\n",
    "def read_perstage_file(f: Path) -> Optional[pd.DataFrame]:\n",
    "    df = pd.read_csv(f)\n",
    "    t = _pick(df, COL_TIME)\n",
    "    s = _pick(df, COL_SAMPLE)\n",
    "    v_inc = _pick(df, COL_VALUE_INCREMENTAL)\n",
    "    v_cum = _pick(df, COL_VALUE_CUMULATIVE)\n",
    "    if DEBUG_SCAN:\n",
    "        print(f\"[PICK] {f.name}: time={t}, sample={s}, inc={v_inc}, cum={v_cum}\")\n",
    "    if not (t and s and (v_inc or v_cum)): \n",
    "        return None\n",
    "    out = df[[t, s, (v_inc or v_cum)]].rename(columns={t:\"t\", s:\"sample\", (v_inc or v_cum):\"value\"}).copy()\n",
    "    out = _coerce_time_inplace(out, \"t\")\n",
    "    out[\"is_incremental\"] = v_inc is not None\n",
    "    return out\n",
    "\n",
    "def cum_from_tidy(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.sort_values([\"sample\",\"t\"]).copy()\n",
    "    if \"is_incremental\" in df and df[\"is_incremental\"].iloc[0]:\n",
    "        df[\"cum\"] = df.groupby(\"sample\")[\"value\"].cumsum()\n",
    "    else:\n",
    "        df[\"cum\"] = df[\"value\"]\n",
    "    return df\n",
    "\n",
    "# -------- figures ----------\n",
    "def std_last5_over_time(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.sort_values([\"sample\",\"t\"])\n",
    "    last5 = sorted(df[\"sample\"].unique())[-5:]\n",
    "    df5 = cum_from_tidy(df[df[\"sample\"].isin(last5)].copy())\n",
    "    wide = df5.pivot_table(index=\"t\", columns=\"sample\", values=\"cum\", aggfunc=\"last\").sort_index()\n",
    "    return pd.DataFrame({\"t\": wide.index, \"std_last5\": wide.std(axis=1, ddof=1)})\n",
    "\n",
    "def plot_std_time(series_by_N: Dict[int, pd.DataFrame], title: str, out_png: Path, out_pdf: Path):\n",
    "    if not series_by_N: \n",
    "        print(f\"[WARN] Nothing to plot for {title}.\"); return\n",
    "    plt.figure(figsize=(8,5.2))\n",
    "    for N, d in sorted(series_by_N.items()):\n",
    "        plt.plot(d[\"t\"], d[\"std_last5\"], label=f\"{N} samples\")\n",
    "    plt.xlabel(\"Time (h)\"); plt.ylabel(\"Standard deviation of last five samples ($)\")\n",
    "    plt.legend(); plt.tight_layout()\n",
    "    out_png.parent.mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig(out_png, dpi=300); plt.savefig(out_pdf); plt.close()\n",
    "    print(f\"[OK] wrote {out_png} (+pdf)\")\n",
    "\n",
    "def build_std_figures_for(root: Path, label: str):\n",
    "    found = discover_perstage_files(root)                 # {N: path}\n",
    "    if not found: \n",
    "        print(f\"[WARN] No per-stage files found in {root}\"); \n",
    "        return\n",
    "    series = {}\n",
    "    for N, f in found.items():\n",
    "        df = read_perstage_file(f)\n",
    "        if df is None or df.empty:\n",
    "            print(f\"[WARN] {label}: cannot read time-series from {f.name}\")\n",
    "            continue\n",
    "        series[N] = std_last5_over_time(df)\n",
    "    plot_std_time(series, f\"{label}: Std of last five samples\",\n",
    "                  Path(f\"figures/{label.lower()}_std_last5.png\"),\n",
    "                  Path(f\"figures/{label.lower()}_std_last5.pdf\"))\n",
    "    return found  # so we can reuse for the two-panel\n",
    "\n",
    "def build_two_panel_for(root: Path, label: str):\n",
    "    found = discover_perstage_files(root)\n",
    "    if len(found) < 2:\n",
    "        print(f\"[WARN] Need at least two Ns for {label} panel; found: {list(found.keys())}\")\n",
    "        return\n",
    "    N_small, N_large = min(found), max(found)\n",
    "    df_small = read_perstage_file(found[N_small])\n",
    "    df_large = read_perstage_file(found[N_large])\n",
    "    if df_small is None or df_large is None:\n",
    "        print(f\"[WARN] Could not read panel data for {label}\")\n",
    "        return\n",
    "    df_small = cum_from_tidy(df_small); df_large = cum_from_tidy(df_large)\n",
    "    fig, axes = plt.subplots(1,2, figsize=(10,4.2), sharey=True)\n",
    "    for ax, (df, N) in zip(axes, [(df_small, N_small), (df_large, N_large)]):\n",
    "        last5 = sorted(df[\"sample\"].unique())[-5:]\n",
    "        for sid in last5:\n",
    "            sub = df[df[\"sample\"]==sid]\n",
    "            ax.plot(sub[\"t\"], sub[\"cum\"])\n",
    "        ax.set_xlabel(\"Time (h)\"); ax.set_title(f\"Last five samples\\nout of N={N}\")\n",
    "        ax.grid(True, linestyle=\":\", alpha=0.6)\n",
    "    axes[0].set_ylabel(\"Estimate of post-decision value ($)\")\n",
    "    fig.suptitle(f\"{label}: Value estimates for last five samples\", y=1.02)\n",
    "    fig.tight_layout()\n",
    "    out_png = Path(f\"figures/{label.lower()}_last5_two_panel.png\")\n",
    "    out_pdf = Path(f\"figures/{label.lower()}_last5_two_panel.pdf\")\n",
    "    out_png.parent.mkdir(parents=True, exist_ok=True)\n",
    "    fig.savefig(out_png, dpi=300, bbox_inches=\"tight\"); fig.savefig(out_pdf, bbox_inches=\"tight\"); plt.close(fig)\n",
    "    print(f\"[OK] wrote {out_png} (+pdf)\")\n",
    "    \n",
    "# ===================== RUNTIME vs N (ADP & SDDP) =====================\n",
    "from glob import glob\n",
    "\n",
    "RUNTIME_COLS = [\"runtime_sec\", \"elapsed\", \"wall_time\", \"time_sec\", \"seconds\", \"duration\"]\n",
    "N_COLS       = [\"N\", \"n\", \"samples\", \"num_samples\"]\n",
    "\n",
    "def _read_summary_allN(root: Path) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"Find *summary_allN*.csv in root, return tidy df with columns N, runtime.\"\"\"\n",
    "    files = sorted(glob(str(root / \"*summary_allN*.csv\")))\n",
    "    if not files:\n",
    "        return None\n",
    "    df = pd.read_csv(files[0])\n",
    "    cN = _pick(df, N_COLS)\n",
    "    ct = _pick(df, RUNTIME_COLS)\n",
    "    if not (cN and ct):\n",
    "        return None\n",
    "    out = df[[cN, ct]].rename(columns={cN: \"N\", ct: \"runtime\"}).copy()\n",
    "    out[\"N\"] = pd.to_numeric(out[\"N\"], errors=\"coerce\")\n",
    "    out[\"runtime\"] = pd.to_numeric(out[\"runtime\"], errors=\"coerce\")\n",
    "    out = out.dropna().sort_values(\"N\").reset_index(drop=True)\n",
    "    return out\n",
    "\n",
    "def build_runtime_vs_samples():\n",
    "    adp   = _read_summary_allN(DIR_ADP)\n",
    "    sddp  = _read_summary_allN(DIR_SDDP)\n",
    "    adpuc = _read_summary_allN(DIR_ADPUC)   # NEW\n",
    "\n",
    "    if (adp is None or adp.empty) and (sddp is None or sddp.empty) and (adpuc is None or adpuc.empty):\n",
    "        print(\"[WARN] No *summary_allN* files found; skipping runtime plot.\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(7.2, 4.6))\n",
    "    if adp is not None and not adp.empty:\n",
    "        plt.plot(adp[\"runtime\"], adp[\"N\"], marker=\"o\", label=\"ADP\")\n",
    "    if sddp is not None and not sddp.empty:\n",
    "        plt.plot(sddp[\"runtime\"], sddp[\"N\"], marker=\"s\", label=\"SDDP\")\n",
    "    if adpuc is not None and not adpuc.empty:\n",
    "        plt.plot(adpuc[\"runtime\"], adpuc[\"N\"], marker=\"^\", label=\"ADP-UC\")  # NEW\n",
    "\n",
    "    plt.xlabel(\"Runtime\")\n",
    "    plt.ylabel(\"Number of samples (N)\")\n",
    "    plt.grid(True, linestyle=\":\", alpha=0.6)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    out_png = Path(\"figures/runtime_vs_samples.png\")\n",
    "    out_pdf = Path(\"figures/runtime_vs_samples.pdf\")\n",
    "    out_png.parent.mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig(out_png, dpi=300); plt.savefig(out_pdf); plt.close()\n",
    "    print(f\"[OK] Wrote {out_png} (+pdf)\")\n",
    "\n",
    "\n",
    "\n",
    "# ============ ACCUMULATED DIFF IN PROFIT BY ITER (N=1000) ====================\n",
    "ITER_COLS  = [\"iter\", \"iteration\", \"k\"]\n",
    "PATH_COLS  = [\"path_id\", \"path\", \"sample\", \"id\", \"sample_id\"]\n",
    "VAL_COLS   = [\"obj\", \"objective\", \"profit\", \"value\", \"obj_total\"]\n",
    "\n",
    "def _per_iter_profit_from_perpath(root: Path, N: int) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"Prefer per-path eval files; columns expected to include iter + a profit/obj value.\"\"\"\n",
    "    for pat in [f\"*train_eval_perpath*N{N}.csv\", f\"*test_perpath*N{N}.csv\"]:\n",
    "        for f in sorted(root.glob(pat)):\n",
    "            df = pd.read_csv(f)\n",
    "            cit  = _pick(df, ITER_COLS)\n",
    "            cval = _pick(df, VAL_COLS)\n",
    "            if not (cit and cval):\n",
    "                continue\n",
    "            out = df[[cit, cval]].rename(columns={cit: \"iter\", cval: \"profit\"}).copy()\n",
    "            out[\"iter\"] = pd.to_numeric(out[\"iter\"], errors=\"coerce\")\n",
    "            out[\"profit\"] = pd.to_numeric(out[\"profit\"], errors=\"coerce\")\n",
    "            out = out.dropna().groupby(\"iter\", as_index=False)[\"profit\"].mean()\n",
    "            return out.sort_values(\"iter\").reset_index(drop=True)\n",
    "    return None\n",
    "\n",
    "def _per_iter_profit_from_perstage(root: Path, N: int) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Fallback: from per-stage file, take the cumulative objective ('obj' / similar)\n",
    "    at the LAST stage of each (iter, path), then average across paths per iteration.\n",
    "    \"\"\"\n",
    "    hits = sorted(root.glob(f\"*train_perstage*N{N}.csv\"))\n",
    "    if not hits:\n",
    "        return None\n",
    "    df = pd.read_csv(hits[0])\n",
    "    cit  = _pick(df, ITER_COLS)\n",
    "    cpa  = _pick(df, PATH_COLS)\n",
    "    cti  = _pick(df, [\"t\", \"stage\", \"Stage\", \"time\", \"hour\", \"k\"])\n",
    "    cval = _pick(df, VAL_COLS + [\"obj_stage\"])\n",
    "    if not (cit and cpa and cti and cval):\n",
    "        return None\n",
    "\n",
    "    df[cti] = pd.to_numeric(df[cti], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[cti]).copy()\n",
    "    last_t = df.groupby([cit, cpa], as_index=False)[cti].max()\n",
    "    dfm = pd.merge(last_t, df[[cit, cpa, cti, cval]], on=[cit, cpa, cti], how=\"left\")\n",
    "    out = dfm.groupby(cit, as_index=False)[cval].mean().rename(columns={cit: \"iter\", cval: \"profit\"})\n",
    "    out[\"iter\"] = pd.to_numeric(out[\"iter\"], errors=\"coerce\")\n",
    "    out = out.dropna().sort_values(\"iter\").reset_index(drop=True)\n",
    "    return out\n",
    "\n",
    "def _per_iter_profit(root: Path, N: int) -> Optional[pd.DataFrame]:\n",
    "    return _per_iter_profit_from_perpath(root, N) or _per_iter_profit_from_perstage(root, N)\n",
    "\n",
    "def _load_cum_abs_delta_series(root: Path, N: int) -> Optional[pd.Series]:\n",
    "    hits = sorted(root.glob(f\"*history*N{N}.csv\"))  # matches adp_uc_history_N1000.csv etc.\n",
    "    if not hits:\n",
    "        return None\n",
    "    df = pd.read_csv(hits[0])\n",
    "    if \"cum_abs_delta\" not in df.columns:\n",
    "        return None\n",
    "    s = pd.to_numeric(df[\"cum_abs_delta\"], errors=\"coerce\")\n",
    "    s = s.reset_index(drop=True)  # iteration index = 1..len\n",
    "    s.index = np.arange(1, len(s) + 1)\n",
    "    return s.dropna()\n",
    "\n",
    "def plot_cum_abs_delta_from_history(N: int = 1000):\n",
    "    A  = _load_cum_abs_delta_series(DIR_ADP,   N)\n",
    "    S  = _load_cum_abs_delta_series(DIR_SDDP,  N)\n",
    "    U  = _load_cum_abs_delta_series(DIR_ADPUC, N)   # NEW\n",
    "\n",
    "    if (A is None) and (S is None) and (U is None):\n",
    "        print(f\"[WARN] No history cum_abs_delta for N={N}; skipping.\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(8, 4.8))\n",
    "    if A is not None: plt.plot(A.index, A.values, label=\"ADP: cum_abs_delta\")\n",
    "    if S is not None: plt.plot(S.index, S.values, label=\"SDDP: cum_abs_delta\")\n",
    "    if U is not None: plt.plot(U.index, U.values, label=\"ADP-UC: cum_abs_delta\")  # NEW\n",
    "    plt.xlabel(\"Iteration\"); plt.ylabel(\"Cumulative |Δ profit| ($)\")\n",
    "    plt.title(f\"Cumulative absolute profit change (N={N})\")\n",
    "    plt.grid(True, linestyle=\":\", alpha=0.6)\n",
    "    plt.legend(); plt.tight_layout()\n",
    "    out_png = Path(f\"figures/cum_abs_delta_hist_N{N}.png\")\n",
    "    out_pdf = Path(f\"figures/cum_abs_delta_hist_N{N}.pdf\")\n",
    "    out_png.parent.mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig(out_png, dpi=300); plt.savefig(out_pdf); plt.close()\n",
    "    print(f\"[OK] Wrote {out_png} (+pdf)\")\n",
    "\n",
    "\n",
    "# ---------- Read EEV/WS by N from a single summary.csv and plot Δ to methods -----\n",
    "\n",
    "EEV_COL_CANDS_OUT = [\"EEV_out\", \"EEV_out_of_sample\", \"eev_out\", \"eev_oos\"]\n",
    "EEV_COL_CANDS_IN  = [\"EEV_in\", \"EEV_in_sample\", \"eev_in\", \"eev_is\", \"EEV\"]\n",
    "WS_COL_CANDS_OUT  = [\"WS_out\", \"WS_out_of_sample\", \"ws_out\", \"ws_oos\"]\n",
    "WS_COL_CANDS_IN   = [\"WS_in\", \"WS_in_sample\", \"ws_in\", \"ws_is\", \"WS\"]\n",
    "N_COL_CANDS       = [\"N\", \"n\", \"samples\", \"num_samples\"]\n",
    "\n",
    "def _load_summary_eev_ws() -> Optional[pd.DataFrame]:\n",
    "    \"\"\"Load summary.csv (EEV/WS by N) from results_eev_ws/ or project root.\"\"\"\n",
    "    for base in [DIR_EEVWS, Path(\".\")]:\n",
    "        f = base / \"summary.csv\"\n",
    "        if f.exists():\n",
    "            df = pd.read_csv(f)\n",
    "            # pick N\n",
    "            cN = _pick(df, N_COL_CANDS)\n",
    "            if not cN:\n",
    "                print(f\"[WARN] {f} has no N column. Found: {list(df.columns)}\"); \n",
    "                continue\n",
    "            # choose out-of-sample if available, else in-sample\n",
    "            ceev = (_pick(df, EEV_COL_CANDS_OUT) or _pick(df, EEV_COL_CANDS_IN))\n",
    "            cws  = (_pick(df, WS_COL_CANDS_OUT)  or _pick(df, WS_COL_CANDS_IN))\n",
    "            if not ceev and not cws:\n",
    "                print(f\"[WARN] {f} has neither EEV nor WS columns I recognize.\")\n",
    "                continue\n",
    "            out = df[[cN] + [c for c in [ceev, cws] if c]].rename(\n",
    "                columns={cN:\"N\", (ceev or \"EEV\"):\"EEV\", (cws or \"WS\"):\"WS\"}\n",
    "            ).copy()\n",
    "            out[\"N\"]  = pd.to_numeric(out[\"N\"], errors=\"coerce\")\n",
    "            if \"EEV\" in out: out[\"EEV\"] = pd.to_numeric(out[\"EEV\"], errors=\"coerce\")\n",
    "            if \"WS\"  in out: out[\"WS\"]  = pd.to_numeric(out[\"WS\"],  errors=\"coerce\")\n",
    "            out = out.dropna(subset=[\"N\"]).sort_values(\"N\").reset_index(drop=True)\n",
    "            print(f\"[OK] Loaded EEV/WS summary from {f}\")\n",
    "            return out\n",
    "    print(\"[WARN] Could not find summary.csv for EEV/WS.\")\n",
    "    return None\n",
    "\n",
    "def _profit_at_last_iteration(root: Path, N: int) -> Optional[float]:\n",
    "    \"\"\"(Reuse from earlier) – returns scalar mean profit at last iter for a method.\"\"\"\n",
    "    # preferred: per-path eval; fallback: per-stage last stage\n",
    "    for pat in [f\"*train_eval_perpath*N{N}.csv\", f\"*test_perpath*N{N}.csv\"]:\n",
    "        hits = sorted(root.glob(pat))\n",
    "        for f in hits:\n",
    "            df = pd.read_csv(f)\n",
    "            cit = _pick(df, [\"iter\",\"iteration\",\"k\"])\n",
    "            cval = _pick(df, [\"obj\",\"objective\",\"profit\",\"value\",\"obj_total\"])\n",
    "            if not (cit and cval): \n",
    "                continue\n",
    "            s = (df[[cit,cval]].rename(columns={cit:\"iter\", cval:\"profit\"})\n",
    "                   .assign(iter=lambda d: pd.to_numeric(d[\"iter\"], errors=\"coerce\"),\n",
    "                           profit=lambda d: pd.to_numeric(d[\"profit\"], errors=\"coerce\"))\n",
    "                   .dropna().groupby(\"iter\")[\"profit\"].mean().sort_index())\n",
    "            if not s.empty:\n",
    "                return float(s.iloc[-1])\n",
    "    # fallback per-stage\n",
    "    hits = sorted(root.glob(f\"*train_perstage*N{N}.csv\"))\n",
    "    if not hits: return None\n",
    "    df = pd.read_csv(hits[0])\n",
    "    cit  = _pick(df, [\"iter\",\"iteration\",\"k\"])\n",
    "    cpa  = _pick(df, [\"path_id\",\"path\",\"sample\",\"id\",\"sample_id\"])\n",
    "    cti  = _pick(df, [\"t\",\"stage\",\"Stage\",\"time\",\"hour\",\"k\"])\n",
    "    cval = _pick(df, [\"obj\",\"objective\",\"profit\",\"value\",\"obj_total\",\"obj_stage\"])\n",
    "    if not (cit and cpa and cti and cval):\n",
    "        return None\n",
    "    df[cti] = pd.to_numeric(df[cti], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[cti])\n",
    "    last_t = df.groupby([cit,cpa], as_index=False)[cti].max()\n",
    "    dfm = pd.merge(last_t, df[[cit,cpa,cti,cval]], on=[cit,cpa,cti], how=\"left\")\n",
    "    s = (dfm.rename(columns={cit:\"iter\", cval:\"profit\"})\n",
    "            .assign(iter=lambda d: pd.to_numeric(d[\"iter\"], errors=\"coerce\"),\n",
    "                    profit=lambda d: pd.to_numeric(d[\"profit\"], errors=\"coerce\"))\n",
    "            .dropna().groupby(\"iter\")[\"profit\"].mean().sort_index())\n",
    "    return None if s.empty else float(s.iloc[-1])\n",
    "\n",
    "def build_delta_vs_N_from_summary(plot_ws: bool=False):\n",
    "    summ = _load_summary_eev_ws()\n",
    "    if summ is None or summ.empty or \"EEV\" not in summ:\n",
    "        print(\"[WARN] No usable EEV data in summary.csv; skipping Δ vs N plot.\")\n",
    "        return\n",
    "\n",
    "    Ns = list(map(int, sorted(summ[\"N\"].dropna().unique())))\n",
    "    rows = []\n",
    "    for N in Ns:\n",
    "        eev = float(summ.loc[summ[\"N\"]==N, \"EEV\"].dropna().iloc[0]) if (summ[\"N\"]==N).any() else None\n",
    "        ws  = float(summ.loc[summ[\"N\"]==N, \"WS\"].dropna().iloc[0])  if (\"WS\" in summ and (summ[\"N\"]==N).any()) else None\n",
    "        adp   = _profit_at_last_iteration(DIR_ADP,   N)\n",
    "        sddp  = _profit_at_last_iteration(DIR_SDDP,  N)\n",
    "        adpuc = _profit_at_last_iteration(DIR_ADPUC, N)   # NEW\n",
    "        rows.append({\n",
    "            \"N\": N,\n",
    "            \"Δ(EEV−ADP)\":    None if (eev is None or adp   is None) else eev - adp,\n",
    "            \"Δ(EEV−SDDP)\":   None if (eev is None or sddp  is None) else eev - sddp,\n",
    "            \"Δ(EEV−ADP-UC)\": None if (eev is None or adpuc is None) else eev - adpuc,  # NEW\n",
    "            \"Δ(WS−ADP)\":     None if (ws  is None or adp   is None) else ws  - adp,\n",
    "            \"Δ(WS−SDDP)\":    None if (ws  is None or sddp  is None) else ws  - sddp,\n",
    "            \"Δ(WS−ADP-UC)\":  None if (ws  is None or adpuc is None) else ws  - adpuc,\n",
    "        })\n",
    "    df = pd.DataFrame(rows).dropna(subset=[\"N\"]).sort_values(\"N\")\n",
    "    if df.empty:\n",
    "        print(\"[WARN] No overlapping N between summary.csv and method profits.\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(8, 4.8))\n",
    "    if df[\"Δ(EEV−ADP)\"].notna().any():\n",
    "        plt.plot(df[\"N\"], df[\"Δ(EEV−ADP)\"], marker=\"o\", label=\"EEV − ADP\")\n",
    "    if df[\"Δ(EEV−SDDP)\"].notna().any():\n",
    "        plt.plot(df[\"N\"], df[\"Δ(EEV−SDDP)\"], marker=\"s\", label=\"EEV − SDDP\")\n",
    "    if df[\"Δ(EEV−ADP-UC)\"].notna().any():\n",
    "        plt.plot(df[\"N\"], df[\"Δ(EEV−ADP-UC)\"], marker=\"^\", label=\"EEV − ADP-UC\")  # NEW\n",
    "\n",
    "    if plot_ws:\n",
    "        if \"Δ(WS−ADP)\" in df and df[\"Δ(WS−ADP)\"].notna().any():\n",
    "            plt.plot(df[\"N\"], df[\"Δ(WS−ADP)\"], linestyle=\"--\", marker=\"o\", label=\"WS − ADP\")\n",
    "        if \"Δ(WS−SDDP)\" in df and df[\"Δ(WS−SDDP)\"].notna().any():\n",
    "            plt.plot(df[\"N\"], df[\"Δ(WS−SDDP)\"], linestyle=\"--\", marker=\"s\", label=\"WS − SDDP\")\n",
    "        if \"Δ(WS−ADP-UC)\" in df and df[\"Δ(WS−ADP-UC)\"].notna().any():\n",
    "            plt.plot(df[\"N\"], df[\"Δ(WS−ADP-UC)\"], linestyle=\"--\", marker=\"^\", label=\"WS − ADP-UC\")\n",
    "\n",
    "    plt.axhline(0.0, color=\"k\", linewidth=0.8)\n",
    "    plt.xlabel(\"Number of samples (N)\")\n",
    "    plt.ylabel(\"Profit difference ($)\")\n",
    "    plt.title(\"Difference to EEV by N\" + (\" (WS included)\" if plot_ws else \"\"))\n",
    "    plt.grid(True, linestyle=\":\", alpha=0.6)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    out_png = Path(\"figures/delta_to_eev_vs_N.png\" if not plot_ws else \"figures/delta_to_eev_ws_vs_N.png\")\n",
    "    out_pdf = out_png.with_suffix(\".pdf\")\n",
    "    out_png.parent.mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig(out_png, dpi=300); plt.savefig(out_pdf); plt.close()\n",
    "    print(f\"[OK] Wrote {out_png} (+pdf)\")\n",
    "\n",
    "\n",
    "# -------- drivers ----------\n",
    "def build_all():\n",
    "    # last-five panels\n",
    "    build_two_panel_for(DIR_ADP,   \"ADP\")\n",
    "    build_two_panel_for(DIR_SDDP,  \"SDDP\")\n",
    "    build_two_panel_for(DIR_ADPUC, \"ADP-UC\")\n",
    "\n",
    "    # std of last five over time\n",
    "    build_std_figures_for(DIR_ADP,   \"ADP\")\n",
    "    build_std_figures_for(DIR_SDDP,  \"SDDP\")\n",
    "    build_std_figures_for(DIR_ADPUC, \"ADP-UC\")\n",
    "\n",
    "    # runtime & convergence-style plots\n",
    "    build_runtime_vs_samples()\n",
    "    plot_cum_abs_delta_from_history(1000)     # ADP, SDDP, ADP-UC\n",
    "    build_delta_vs_N_from_summary(plot_ws=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    build_all()\n",
    "    print(\"Done. See the 'figures/' folder.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
