{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f37f3ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "# Load data (assumes you've generated these already)\n",
    "from Input_generator import generate_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6275b3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== learning rate =====\n",
    "def alpha_schedule(n, alpha0=0.5, power=0.6):\n",
    "    return alpha0 / (n ** power)\n",
    "\n",
    "# ===== helpers to coerce shapes =====\n",
    "def coerce_vec(x, J):\n",
    "    if x is None:\n",
    "        return np.zeros(J)\n",
    "    x = np.asarray(x, dtype=float).reshape(-1)\n",
    "    if x.size == J: return x\n",
    "    if x.size == 1: return np.full(J, float(x[0]))\n",
    "    return np.zeros(J)\n",
    "\n",
    "# ensure b_t is a scalar per stage\n",
    "def coerce_scalar(x):\n",
    "    \"\"\"Return a scalar float from possibly vector/array b_t; default 0.0.\"\"\"\n",
    "    if x is None:\n",
    "        return 0.0\n",
    "    arr = np.asarray(x, dtype=float).reshape(-1)\n",
    "    if arr.size == 0:\n",
    "        return 0.0\n",
    "    # If your training uses a true scalar, this just passes it through.\n",
    "    # If legacy code produced a vector, we take the mean to collapse consistently.\n",
    "    return float(arr.mean())\n",
    "\n",
    "# evaluate linear value function at next stage (t_next is 1-based for V̄_{t_next+1})\n",
    "def eval_vbar_linear(a_list, b_list, t_next, x_post):\n",
    "    \"\"\"\n",
    "    a_list: list length >= t_next+1, each a_t is shape (J,)\n",
    "    b_list: list of scalars (float) per stage\n",
    "    t_next: int, e.g. 1 for V̄2\n",
    "    x_post: shape (J,), post-decision state\n",
    "    \"\"\"\n",
    "    a = np.asarray(a_list[t_next], dtype=float).reshape(-1)   # a_{t_next+1}; since a_list has length T+1 indexed 0..T\n",
    "    b = float(b_list[t_next])                                 # scalar intercept\n",
    "    return float(a @ np.asarray(x_post, float).reshape(-1) + b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4e078b",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "\n",
    "- a) Sample the post-decision value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57d2db6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== single-stage lookahead with linearized future =====\n",
    "def solve_stage_step1a_gurobi_report(\n",
    "    t, n, l_t, rho_t, nu_t, R, l_min, l_max, pi_min, pi_max,\n",
    "    a_next_prev, Vhat_next_prev_scalar, l_next_prev,\n",
    "    gen_coeff=None, verbose=False, soft_bounds=True, bound_penalty_scale=1000.0\n",
    "):\n",
    "    J = l_t.shape[0]\n",
    "    if gen_coeff is None:\n",
    "        gen_coeff = np.ones(J)\n",
    "\n",
    "    m = gp.Model(f\"stage_{n}_{t}\")\n",
    "    if not verbose:\n",
    "        m.Params.OutputFlag = 0\n",
    "\n",
    "    pi = m.addVars(J, lb=pi_min.tolist(), ub=pi_max.tolist(), name=\"pi\")\n",
    "\n",
    "    if soft_bounds:\n",
    "        lnext = m.addVars(J, lb=-GRB.INFINITY, name=\"l_next\")\n",
    "        s_lo  = m.addVars(J, lb=0.0, name=\"s_lo\")\n",
    "        s_hi  = m.addVars(J, lb=0.0, name=\"s_hi\")\n",
    "    else:\n",
    "        lnext = m.addVars(J, lb=l_min.tolist(), ub=l_max.tolist(), name=\"l_next\")\n",
    "        s_lo = s_hi = None\n",
    "\n",
    "    dyn_constr = []\n",
    "    for j in range(J):\n",
    "        expr = gp.LinExpr(l_t[j] + nu_t[j])\n",
    "        for k in range(J):\n",
    "            c = R[j, k]\n",
    "            if c != 0.0:\n",
    "                expr.addTerms(c, pi[k])\n",
    "        dyn_constr.append(m.addConstr(lnext[j] == expr, name=f\"dyn[{j}]\"))\n",
    "\n",
    "    if soft_bounds:\n",
    "        for j in range(J):\n",
    "            m.addConstr(lnext[j] + s_lo[j] >= l_min[j], name=f\"min[{j}]\")\n",
    "            m.addConstr(lnext[j] - s_hi[j] <= l_max[j], name=f\"max[{j}]\")\n",
    "\n",
    "    # decision objective: revenue + linearized future - slack penalty\n",
    "    rev = gp.LinExpr()\n",
    "    for j in range(J):\n",
    "        if gen_coeff[j] != 0.0:\n",
    "            rev.addTerms(rho_t * gen_coeff[j], pi[j])\n",
    "\n",
    "    fut = gp.LinExpr()\n",
    "    for j in range(J):\n",
    "        a = a_next_prev[j]\n",
    "        if a != 0.0:\n",
    "            fut.addTerms(a, lnext[j])\n",
    "\n",
    "    if soft_bounds:\n",
    "        pen_coeff = bound_penalty_scale * (abs(rho_t) + 1.0)\n",
    "        pen_term = pen_coeff * (gp.quicksum(s_lo[j] for j in range(J)) +\n",
    "                                gp.quicksum(s_hi[j] for j in range(J)))\n",
    "        m.setObjective(rev + fut - pen_term, GRB.MAXIMIZE)\n",
    "    else:\n",
    "        pen_coeff = 0.0\n",
    "        m.setObjective(rev + fut, GRB.MAXIMIZE)\n",
    "\n",
    "    m.optimize()\n",
    "    if m.status != GRB.OPTIMAL:\n",
    "        raise RuntimeError(f\"Gurobi not OPTIMAL at (n={n}, t={t}). Status: {m.status}\")\n",
    "\n",
    "    pi_opt    = np.array([pi[j].X for j in range(J)])\n",
    "    lnext_opt = np.array([lnext[j].X for j in range(J)])\n",
    "    lam       = np.array([dyn_constr[j].Pi for j in range(J)])\n",
    "\n",
    "\n",
    "    rev_stage = float(sum(rho_t * gen_coeff[j] * pi_opt[j] for j in range(J)))\n",
    "    penalty_stage = 0.0\n",
    "    if soft_bounds:\n",
    "        s_lo_sum = float(sum(s_lo[j].X for j in range(J)))\n",
    "        s_hi_sum = float(sum(s_hi[j].X for j in range(J)))\n",
    "        penalty_stage = pen_coeff * (s_lo_sum + s_hi_sum)\n",
    "\n",
    "    obj_stage = rev_stage - penalty_stage\n",
    "\n",
    "    # --- post-decision state (AFTER decision, BEFORE inflow): x̄_t = l_t + R π_t\n",
    "    xpost = l_t + R.dot(pi_opt)\n",
    "\n",
    "    return pi_opt, lnext_opt, lam, rev_stage, penalty_stage, obj_stage, xpost\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66af1632",
   "metadata": {},
   "source": [
    "- c) Determine the next pre-decision state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "918a6180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== main ADP exports =====\n",
    "def run_adp_exports_sddp_format(\n",
    "    N, out_dir,\n",
    "    alpha0=0.5, power=0.6, verbose=False\n",
    "):\n",
    "    # Load inputs for this N\n",
    "    (J, T, l_max, l_min, l0, pi_max, pi_min,\n",
    "     price_samples, inflow_samples, nu0, rho0, R,\n",
    "     a_t_init, b_t_init, l_bar, alpha_energy) = generate_input(N)\n",
    "\n",
    "    l_min = np.asarray(l_min, dtype=float); l_max = np.asarray(l_max, dtype=float)\n",
    "    l0    = np.asarray(l0, dtype=float)\n",
    "    pi_min = np.asarray(pi_min, dtype=float); pi_max = np.asarray(pi_max, dtype=float)\n",
    "    R = np.asarray(R, dtype=float)\n",
    "    price_samples = np.asarray(price_samples, dtype=float)\n",
    "    inflow_samples = np.asarray(inflow_samples, dtype=float)\n",
    "    gen_coeff = np.asarray(alpha_energy if alpha_energy is not None else np.ones(J), dtype=float)\n",
    "\n",
    "    # supergradients a_t : length T+1 (index 0..T). Keep a_0 unused; a_{t} used with stage t.\n",
    "    a_t = [coerce_vec(a_t_init[t] if t < len(a_t_init) else None, J) for t in range(T+1)]\n",
    "\n",
    "    ### FIX/NEW: scalar intercepts b_t per stage (length T+1). Use 0.0 if not trained yet.\n",
    "    b_t = [coerce_scalar(b_t_init[t] if t < len(b_t_init) else None) for t in range(T+1)]\n",
    "\n",
    "    # baselines (not exported)\n",
    "    Vhat_prev  = np.zeros(T+1)\n",
    "    l_prev_pre = np.zeros((T+1, J)); l_prev_pre[0] = l0.copy()\n",
    "\n",
    "    first_hour_rows = []\n",
    "    paths_rows = []\n",
    "    obj_totals = []\n",
    "\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    t0 = time.perf_counter()\n",
    "\n",
    "    for n in range(1, N+1):\n",
    "        alpha_n = alpha_schedule(n, alpha0=alpha0, power=power)\n",
    "        price_path  = price_samples[n-1]\n",
    "        inflow_path = inflow_samples[n-1]\n",
    "\n",
    "        l_t = l0.copy()\n",
    "\n",
    "        # Prepare the first-hour row; fill vbar AFTER solving t=0.  ### MOVED\n",
    "        fh_row = {\n",
    "            \"path\": n-1,\n",
    "            \"theta1\": 0.0,                    # keep as-is unless you add cuts\n",
    "            \"vbar2_at_xpost1\": 0.0,           # will be overwritten after t==0 solve\n",
    "            \"price1\": float(price_path[0]),\n",
    "        }\n",
    "        for j in range(J):\n",
    "            fh_row[f\"inflow1_res{j+1}\"] = float(inflow_path[0, j])\n",
    "\n",
    "        obj_total = 0.0\n",
    "        for t in range(T):\n",
    "            rho_t = float(price_path[t])\n",
    "            nu_t  = inflow_path[t].astype(float)   # inflow (exogenous)\n",
    "\n",
    "            a_next_prev = a_t[t+1]                 # this is a_{t+1}\n",
    "            Vhat_next_prev_scalar = Vhat_prev[t+1] # unused but kept for interface parity\n",
    "            l_next_prev = l_prev_pre[t+1]          # unused placeholder\n",
    "\n",
    "            (pi_opt, lnext_opt, lam,\n",
    "             rev_stage, penalty_stage, obj_stage, xpost) = solve_stage_step1a_gurobi_report(\n",
    "                t, n, l_t, rho_t, nu_t, R, l_min, l_max, pi_min, pi_max,\n",
    "                a_next_prev, Vhat_next_prev_scalar, l_next_prev,\n",
    "                gen_coeff=gen_coeff, verbose=verbose, soft_bounds=True\n",
    "            )\n",
    "\n",
    "            # === NEW: after solving stage 0, compute V̄2 at x̄1 and store it ===\n",
    "            if t == 0:\n",
    "                # Evaluate V̄2(x̄1) = a_2^T x̄1 + b_2\n",
    "                vbar2 = eval_vbar_linear(a_t, b_t, t_next=1, x_post=xpost)\n",
    "                fh_row[\"vbar2_at_xpost1\"] = float(vbar2)\n",
    "\n",
    "            row = {\n",
    "                \"path\": n-1,\n",
    "                \"stage\": t+1,\n",
    "                \"price\": rho_t,\n",
    "                \"obj_stage\": obj_stage,\n",
    "                \"rev_stage\": rev_stage,\n",
    "                \"penalty_stage\": penalty_stage,\n",
    "                \"util_alg\": obj_stage,  # same for export\n",
    "                \"theta\": 0.0,\n",
    "                \"v_est\": 0.0,\n",
    "            }\n",
    "            for j in range(J):\n",
    "                row[f\"pi{j+1}\"]     = float(pi_opt[j])\n",
    "                row[f\"l{j+1}\"]      = float(l_t[j])\n",
    "                row[f\"xpost{j+1}\"]  = float(xpost[j])\n",
    "                row[f\"inflow{j+1}\"] = float(nu_t[j])\n",
    "\n",
    "            obj_total += obj_stage\n",
    "            paths_rows.append(row)\n",
    "\n",
    "            # Step 1(b) stochastic gradient update using multipliers (skip at t=0 if you want)\n",
    "            if t > 0:\n",
    "                a_t[t] = (1.0 - alpha_n) * a_t[t] + alpha_n * lam\n",
    "                # If you also learn an intercept, update b_t[t] here using your chosen rule.\n",
    "\n",
    "            # Step 1(c) move to next state\n",
    "            l_t = lnext_opt.copy()\n",
    "\n",
    "        # Now that vbar2 is filled, append first-hour row  ### MOVED\n",
    "        first_hour_rows.append(fh_row)\n",
    "\n",
    "        # add total row\n",
    "        paths_rows.append({\"path\": n-1, \"stage\": \"total\", \"obj_total\": obj_total})\n",
    "        obj_totals.append(obj_total)\n",
    "\n",
    "        # (Step 2 baselines not used for export)\n",
    "        Vhat_prev[:] = 0.0\n",
    "        l_prev_pre[:] = 0.0\n",
    "\n",
    "    runtime_hours = (time.perf_counter() - t0) / 3600.0\n",
    "\n",
    "    # write per-N CSVs (all into the SAME folder)\n",
    "    pd.DataFrame(first_hour_rows).to_csv(os.path.join(out_dir, f\"run_N{N}_first_hour.csv\"), index=False)\n",
    "\n",
    "    base_cols = [\"path\",\"stage\",\"price\",\"obj_stage\",\"rev_stage\",\"penalty_stage\",\"util_alg\",\"theta\",\"v_est\"]\n",
    "    per_res_cols = []\n",
    "    for j in range(J):\n",
    "        per_res_cols += [f\"pi{j+1}\", f\"l{j+1}\", f\"xpost{j+1}\", f\"inflow{j+1}\"]\n",
    "    ordered_cols = base_cols + per_res_cols + [\"obj_total\"]\n",
    "    df_paths = pd.DataFrame(paths_rows).reindex(columns=ordered_cols)\n",
    "    df_paths.to_csv(os.path.join(out_dir, f\"run_N{N}_paths.csv\"), index=False)\n",
    "\n",
    "    obj_arr = np.array(obj_totals, dtype=float)\n",
    "    df_summary = pd.DataFrame([{\n",
    "        \"N\": N,\n",
    "        \"paths\": N,\n",
    "        \"avg_obj_total\": obj_arr.mean() if obj_arr.size else 0.0,\n",
    "        \"p10_obj_total\": float(np.percentile(obj_arr, 10)) if obj_arr.size else 0.0,\n",
    "        \"p50_obj_total\": float(np.percentile(obj_arr, 50)) if obj_arr.size else 0.0,\n",
    "        \"p90_obj_total\": float(np.percentile(obj_arr, 90)) if obj_arr.size else 0.0,\n",
    "        \"runtime_hours\": runtime_hours\n",
    "    }])\n",
    "    df_summary.to_csv(os.path.join(out_dir, f\"run_N{N}_summary.csv\"), index=False)\n",
    "\n",
    "    return df_summary.iloc[0].to_dict()\n",
    "\n",
    "# ---------- sweep N=100..1000 and aggregate ----------\n",
    "def run_all_N_sddp_format(out_dir=\"adp_results\"):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    all_rows = []\n",
    "    for N in range(100, 1001, 100):\n",
    "        row = run_adp_exports_sddp_format(N, out_dir=out_dir)\n",
    "        all_rows.append(row)\n",
    "    pd.DataFrame(all_rows).to_csv(os.path.join(out_dir, \"run_summary_allN.csv\"), index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e7fb431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2026-03-26\n",
      "Done. All files saved in: adp_results/\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    run_all_N_sddp_format(out_dir=\"adp_results\")\n",
    "    print(\"Done. All files saved in: adp_results/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
