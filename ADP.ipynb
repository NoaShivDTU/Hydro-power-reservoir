{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b2d3a3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB, quicksum\n",
    "from Input_generator import generate_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5f8c5a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ------------------------- Config -------------------------\n",
    "\n",
    "GAMMA = 1.0\n",
    "MAX_ITERS = 30\n",
    "OUT_PREFIX = \"adp_alg6\"\n",
    "OUTPUT_DIR = \"results_sddp\"\n",
    "SEED_TRAIN = 0\n",
    "\n",
    "# logging controls (keep RAM/files small)\n",
    "LOG_LAST_ITER_ONLY = True\n",
    "LOG_MAX_PATHS = 200\n",
    "\n",
    "# stepsize α_n\n",
    "def alpha_schedule(n, alpha0=0.5, power=0.6):\n",
    "    return alpha0 / (n ** power)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3c410c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ------------------------- Small helpers -------------------------\n",
    "\n",
    "def eval_vbar_linear(a_list, b_list, t_next, x_post):\n",
    "    \"\"\"V̄_{t+1}(x_post) = a_{t+1}^T x_post + b_{t+1} ; t_next is the stage index (0-based).\"\"\"\n",
    "    a = np.asarray(a_list[t_next+1], dtype=float).reshape(-1)\n",
    "    b = float(b_list[t_next+1])\n",
    "    return float(a @ np.asarray(x_post, float).reshape(-1) + b)\n",
    "\n",
    "# ------------------------- Single-stage solve -------------------------\n",
    "\n",
    "def solve_stage(\n",
    "    t, l_t, rho_t, nu_t, R, l_min, l_max, pi_min, pi_max,\n",
    "    a_next, b_next, gen_coeff=None, soft_bounds=True, penalty_scale=1e6, silent=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Solve one forward stage with linearized next value:\n",
    "      maximize  sum_j rho_t * g_j * pi_j  +  a_{t+1}^T l_{t+1} + b_{t+1}  - penalty\n",
    "      s.t.      l_{t+1} = l_t + nu_t + R*pi\n",
    "                (soft) l_min <= l_{t+1} <= l_max\n",
    "\n",
    "    Returns: (obj, pi*, l_next*, duals λ on balance, theta_est=a^T l_next + b, x_post=l_t + R*pi)\n",
    "    \"\"\"\n",
    "    J = l_t.size\n",
    "    if gen_coeff is None:\n",
    "        gen_coeff = np.ones(J, dtype=float)\n",
    "\n",
    "    with gp.Model(f\"stage_t{t}\") as m:\n",
    "        if silent:\n",
    "            m.Params.OutputFlag = 0\n",
    "        m.Params.Threads = 1\n",
    "\n",
    "        pi    = m.addVars(J, lb=pi_min.tolist(), ub=pi_max.tolist(), name=\"pi\")\n",
    "        lnext = m.addVars(J, lb=-GRB.INFINITY if soft_bounds else l_min.tolist(),\n",
    "                             ub= GRB.INFINITY if soft_bounds else l_max.tolist(),\n",
    "                             name=\"l_next\")\n",
    "\n",
    "        # mass balance\n",
    "        bal = []\n",
    "        for j in range(J):\n",
    "            expr = lnext[j] - (float(l_t[j]) + float(nu_t[j]))\n",
    "            expr -= quicksum(float(R[j, k]) * pi[k] for k in range(J))\n",
    "            bal.append(m.addConstr(expr == 0.0, name=f\"bal_{j}\"))\n",
    "\n",
    "        # soft bounds\n",
    "        pen_term = 0.0\n",
    "        if soft_bounds:\n",
    "            s_lo  = m.addVars(J, lb=0.0, name=\"s_lo\")\n",
    "            s_hi  = m.addVars(J, lb=0.0, name=\"s_hi\")\n",
    "            for j in range(J):\n",
    "                m.addConstr(lnext[j] + s_lo[j] >= l_min[j], name=f\"lb_{j}\")\n",
    "                m.addConstr(lnext[j] - s_hi[j] <= l_max[j], name=f\"ub_{j}\")\n",
    "            pen_term = penalty_scale * (quicksum(s_lo[j] for j in range(J)) +\n",
    "                                        quicksum(s_hi[j] for j in range(J)))\n",
    "\n",
    "        # objective = revenue + a^T l_next + b - penalty\n",
    "        rev = quicksum(float(rho_t) * float(gen_coeff[j]) * pi[j] for j in range(J))\n",
    "        fut = quicksum(float(a_next[j]) * lnext[j] for j in range(J)) + float(b_next)\n",
    "        m.setObjective(rev + fut - pen_term, GRB.MAXIMIZE)\n",
    "\n",
    "        m.optimize()\n",
    "        if m.Status not in (GRB.OPTIMAL, GRB.SUBOPTIMAL):\n",
    "            raise RuntimeError(f\"Stage LP infeasible/unbounded at t={t} (status {m.Status})\")\n",
    "\n",
    "        pi_sol = np.array([pi[j].X for j in range(J)], dtype=float)\n",
    "        ln_sol = np.array([lnext[j].X for j in range(J)], dtype=float)\n",
    "        lam    = np.array([c.Pi for c in bal], dtype=float)\n",
    "        theta_est = float(np.dot(a_next, ln_sol) + b_next)\n",
    "        x_post = l_t + R.dot(pi_sol)\n",
    "\n",
    "        return float(m.ObjVal), pi_sol, ln_sol, lam, theta_est, x_post\n",
    "\n",
    "# ------------------------- Policy evaluation -------------------------\n",
    "\n",
    "def evaluate_policy(a_t, b_t, l0, prices, inflow, R, l_min, l_max, pi_min, pi_max, g, gamma=1.0):\n",
    "    \"\"\"Roll out final (a_t, b_t) on provided paths; return per-path totals & first-hour theta.\"\"\"\n",
    "    N_paths, T, J = prices.shape\n",
    "    totals = np.zeros(N_paths, dtype=float)\n",
    "    first_theta = np.zeros(N_paths, dtype=float)\n",
    "\n",
    "    for m in range(N_paths):\n",
    "        l_curr = l0.copy()\n",
    "        acc = 0.0\n",
    "        got_first = False\n",
    "        for t in range(T):\n",
    "            obj, pi_next, l_next, lam, theta, x_post = solve_stage(\n",
    "                t=t, l_t=l_curr, rho_t=float(prices[m, t, 0]),  # price same across j\n",
    "                nu_t=inflow[m, t, :], R=R, l_min=l_min, l_max=l_max,\n",
    "                pi_min=pi_min, pi_max=pi_max, a_next=a_t[t+1], b_next=b_t[t+1],\n",
    "                gen_coeff=g, soft_bounds=True, penalty_scale=1e6, silent=True\n",
    "            )\n",
    "            if not got_first:\n",
    "                first_theta[m] = theta\n",
    "                got_first = True\n",
    "            acc += (gamma ** t) * obj\n",
    "            l_curr = l_next\n",
    "        totals[m] = acc\n",
    "\n",
    "    return pd.DataFrame({\"path_id\": np.arange(N_paths), \"total_profit\": totals, \"first_hour_theta\": first_theta})\n",
    "\n",
    "# ------------------------- Main runner -------------------------\n",
    "\n",
    "def run_adp_like_sddp(\n",
    "    N,\n",
    "    max_iters=MAX_ITERS,\n",
    "    gamma=GAMMA,\n",
    "    seed_train=SEED_TRAIN,\n",
    "    out_prefix=OUT_PREFIX\n",
    "):\n",
    "    t0 = time.time()\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "    # --- generate scenarios ---\n",
    "    gen = generate_input(N)\n",
    "    # Unpack (16-tuple path)\n",
    "    (J, T, l_max, l_min, l0, pi_max, pi_min,\n",
    "     price_samples, inflow_samples, nu0, rho0, R,\n",
    "     a_t0, b_t0, l_bar0, alpha_energy) = gen\n",
    "\n",
    "    # enforce shapes/dtypes\n",
    "    l_min = np.asarray(l_min, dtype=np.float32)\n",
    "    l_max = np.asarray(l_max, dtype=np.float32)\n",
    "    l0    = np.asarray(l0,    dtype=np.float32)\n",
    "    pi_min= np.asarray(pi_min,dtype=np.float32)\n",
    "    pi_max= np.asarray(pi_max,dtype=np.float32)\n",
    "    R     = np.asarray(R,     dtype=np.float32)\n",
    "    g     = np.asarray(alpha_energy, dtype=np.float32)\n",
    "\n",
    "    prices = np.asarray(price_samples, dtype=np.float32)  # (N,T)\n",
    "    inflow = np.asarray(inflow_samples, dtype=np.float32) # (N,T,J)\n",
    "    # broadcast prices to (N,T,J) with same price for each unit\n",
    "    prices = np.repeat(prices[:, :, None], J, axis=2)\n",
    "\n",
    "    # --- split 80/20 ---\n",
    "    N_total = N\n",
    "    N_train = int(0.8 * N_total)\n",
    "    N_test  = N_total - N_train\n",
    "\n",
    "    idx = np.arange(N_total)\n",
    "    rng_state = np.random.get_state()\n",
    "    np.random.seed(seed_train)\n",
    "    np.random.shuffle(idx)\n",
    "    np.random.set_state(rng_state)\n",
    "\n",
    "    id_train = idx[:N_train]\n",
    "    id_test  = idx[N_train:]\n",
    "\n",
    "    prices_train = prices[id_train]\n",
    "    inflow_train = inflow[id_train]\n",
    "    prices_test  = prices[id_test]\n",
    "    inflow_test  = inflow[id_test]\n",
    "\n",
    "    # --- initialize (a_t, b_t) as single cut per stage ---\n",
    "    a_t = [np.zeros(J, dtype=np.float32) for _ in range(T+1)]\n",
    "    b_t = [0.0 for _ in range(T+1)]\n",
    "\n",
    "    # --- logs ---\n",
    "    history = {\"iter\": [], \"avg_forward_value\": [], \"cum_abs_delta\": []}\n",
    "    perstage_rows = []  # last-iteration per-stage logs\n",
    "    cum_abs = 0.0\n",
    "\n",
    "    # ------------------------ training iterations ------------------------\n",
    "    for it in range(1, max_iters + 1):\n",
    "        an = alpha_schedule(it)\n",
    "\n",
    "        # accumulators for Algorithm-6-style updates\n",
    "        sum_omega = np.zeros((T, J), dtype=np.float64)\n",
    "        sum_adjust = np.zeros(T, dtype=np.float64)\n",
    "\n",
    "        path_totals = np.zeros(N_train, dtype=np.float64)\n",
    "\n",
    "        for m in range(N_train):\n",
    "            l_curr = l0.copy()\n",
    "            for t in range(T):\n",
    "                # NOTE: we use one price per stage (same across j)\n",
    "                rho_t = float(prices_train[m, t, 0])\n",
    "                nu_t  = inflow_train[m, t, :]\n",
    "\n",
    "                obj, pi_next, l_next, lam, theta, x_post = solve_stage(\n",
    "                    t=t, l_t=l_curr, rho_t=rho_t, nu_t=nu_t, R=R,\n",
    "                    l_min=l_min, l_max=l_max, pi_min=pi_min, pi_max=pi_max,\n",
    "                    a_next=a_t[t+1], b_next=b_t[t+1], gen_coeff=g,\n",
    "                    soft_bounds=True, penalty_scale=1e6, silent=True\n",
    "                )\n",
    "\n",
    "                # Algorithm-6 averages:\n",
    "                # Vhat_t = obj; adjust = Vhat_t - lam^T l_t\n",
    "                sum_omega[t, :] += lam\n",
    "                sum_adjust[t]   += (obj - float(lam @ l_curr))\n",
    "\n",
    "                # discounted accumulation\n",
    "                path_totals[m] += (gamma ** t) * obj\n",
    "\n",
    "                # last-iteration per-stage logging (capped)\n",
    "                if (not LOG_LAST_ITER_ONLY) or (it == max_iters):\n",
    "                    if m < LOG_MAX_PATHS:\n",
    "                        perstage_rows.append({\n",
    "                            \"N\": N, \"iter\": it, \"path_id\": m, \"t\": t,\n",
    "                            \"obj\": obj, \"theta\": theta\n",
    "                        })\n",
    "\n",
    "                l_curr = l_next\n",
    "\n",
    "        avg_forward = float(np.mean(path_totals))\n",
    "        if it == 1:\n",
    "            cum_abs += 0.0\n",
    "        else:\n",
    "            cum_abs += abs(avg_forward - history[\"avg_forward_value\"][-1])\n",
    "\n",
    "        history[\"iter\"].append(it)\n",
    "        history[\"avg_forward_value\"].append(avg_forward)\n",
    "        history[\"cum_abs_delta\"].append(cum_abs)\n",
    "\n",
    "        # update a_t,b_t with averages across training paths\n",
    "        omega_bar = (sum_omega / max(N_train, 1)).astype(np.float32)\n",
    "        adjust_bar = (sum_adjust / max(N_train, 1)).astype(np.float32)\n",
    "\n",
    "        for t in range(T-1, -1, -1):\n",
    "            a_t[t] = (1.0 - an) * a_t[t] + an * omega_bar[t, :]\n",
    "            b_t[t] = (1.0 - an) * b_t[t] + an * float(adjust_bar[t])\n",
    "\n",
    "        print(f\"  Iter {it:02d}: avg forward value = {avg_forward:,.3f} (cumΔ={cum_abs:,.3f})\")\n",
    "\n",
    "    # ------------------------ save training logs ------------------------\n",
    "    df_hist = pd.DataFrame(history)\n",
    "    df_hist[\"N\"] = N\n",
    "    df_hist.to_csv(os.path.join(OUTPUT_DIR, f\"{OUT_PREFIX}_history_N{N}.csv\"), index=False)\n",
    "\n",
    "    df_train_perstage = pd.DataFrame(perstage_rows)\n",
    "    df_train_perstage.to_csv(os.path.join(OUTPUT_DIR, f\"{OUT_PREFIX}_train_perstage_N{N}.csv\"), index=False)\n",
    "\n",
    "    # ------------------------ evaluation ------------------------\n",
    "    df_eval_train = evaluate_policy(a_t, b_t, l0, prices_train, inflow_train,\n",
    "                                    R, l_min, l_max, pi_min, pi_max, g, gamma=GAMMA)\n",
    "    df_eval_train.to_csv(os.path.join(OUTPUT_DIR, f\"{OUT_PREFIX}_train_eval_perpath_N{N}.csv\"), index=False)\n",
    "\n",
    "    df_eval_test = evaluate_policy(a_t, b_t, l0, prices_test, inflow_test,\n",
    "                                   R, l_min, l_max, pi_min, pi_max, g, gamma=GAMMA)\n",
    "    df_eval_test.to_csv(os.path.join(OUTPUT_DIR, f\"{OUT_PREFIX}_test_perpath_N{N}.csv\"), index=False)\n",
    "\n",
    "    # stats\n",
    "    in_mean  = float(df_eval_train[\"total_profit\"].mean()) if not df_eval_train.empty else 0.0\n",
    "    in_std   = float(df_eval_train[\"total_profit\"].std(ddof=1)) if len(df_eval_train) > 1 else 0.0\n",
    "    test_mean= float(df_eval_test[\"total_profit\"].mean()) if not df_eval_test.empty else 0.0\n",
    "    test_std = float(df_eval_test[\"total_profit\"].std(ddof=1)) if len(df_eval_test) > 1 else 0.0\n",
    "\n",
    "    first_mean = float(df_eval_train[\"first_hour_theta\"].mean()) if not df_eval_train.empty else 0.0\n",
    "    first_std  = float(df_eval_train[\"first_hour_theta\"].std(ddof=1)) if len(df_eval_train) > 1 else 0.0\n",
    "\n",
    "    # ------------------------ save cuts & summary ------------------------\n",
    "    rows = []\n",
    "    for t in range(T+1):\n",
    "        row = {\"stage\": t, \"N\": N, \"b\": float(b_t[t])}\n",
    "        for j in range(J):\n",
    "            row[f\"a_{j}\"] = float(a_t[t][j])\n",
    "        rows.append(row)\n",
    "    pd.DataFrame(rows).to_csv(os.path.join(OUTPUT_DIR, f\"{OUT_PREFIX}_cuts_N{N}.csv\"), index=False)\n",
    "\n",
    "    runtime_sec = time.time() - t0\n",
    "    df_sum = pd.DataFrame([{\n",
    "        \"N\": N,\n",
    "        \"train_size\": N_train, \"test_size\": N_test, \"iters\": MAX_ITERS,\n",
    "        \"runtime_sec\": runtime_sec,\n",
    "        \"final_avg_forward_value\": history[\"avg_forward_value\"][-1],\n",
    "        \"cum_abs_delta\": history[\"cum_abs_delta\"][-1],\n",
    "        \"in_sample_mean\": in_mean, \"in_sample_std\": in_std,\n",
    "        \"test_mean\": test_mean, \"test_std\": test_std,\n",
    "        \"first_hour_theta_mean\": first_mean, \"first_hour_theta_std\": first_std\n",
    "    }])\n",
    "\n",
    "    return ({\"a\": a_t, \"b\": b_t}, {\"history\": df_hist}, df_sum)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bb2b62",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ------------------------- Driver -------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "    all_summaries = []\n",
    "    N = None\n",
    "\n",
    "    if N is None:\n",
    "        for N in range(100, 1001, 100):  # 100, 200, ..., 2000\n",
    "            print(f\"\\n=== Running ADP-like SDDP with N={N} samples ===\")\n",
    "            _, _, df_sum = run_adp_like_sddp(\n",
    "                N=N, max_iters=MAX_ITERS, gamma=GAMMA,\n",
    "                seed_train=SEED_TRAIN, out_prefix=OUT_PREFIX\n",
    "            )\n",
    "            all_summaries.append(df_sum)\n",
    "    else:\n",
    "        print(f\"\\n=== Running ADP-like SDDP with N={N} samples ===\")\n",
    "        _, _, df_sum = run_adp_like_sddp(\n",
    "            N=N, max_iters=MAX_ITERS, gamma=GAMMA,\n",
    "            seed_train=SEED_TRAIN, out_prefix=OUT_PREFIX\n",
    "        )\n",
    "        all_summaries.append(df_sum)\n",
    "\n",
    "    df_all = pd.concat(all_summaries, ignore_index=True)\n",
    "    df_all.to_csv(os.path.join(OUTPUT_DIR, f\"{OUT_PREFIX}_summary_allN.csv\"), index=False)\n",
    "    print(\"\\nDone. Summaries written to\", os.path.abspath(OUTPUT_DIR))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
