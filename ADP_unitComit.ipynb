{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bc4a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB, quicksum\n",
    "from Input_generator import generate_input\n",
    "\n",
    "# ------------------------- Config -------------------------\n",
    "\n",
    "GAMMA = 1.0\n",
    "MAX_ITERS = 30\n",
    "OUT_PREFIX = \"adp_uc_alg6\"\n",
    "OUTPUT_DIR = \"results_adp_unit\"\n",
    "SEED_TRAIN = 0\n",
    "\n",
    "# >>>>>>> Set your startup costs here (one per reservoir/unit) <<<<<<<\n",
    "# If you don't know yet, keep numbers as placeholders and tune later.\n",
    "STARTUP_COSTS = None  # e.g., set to [200.0, 300.0] for (Upper, Lower)\n",
    "\n",
    "# logging controls (keep RAM/files small)\n",
    "LOG_LAST_ITER_ONLY = True\n",
    "LOG_MAX_PATHS = 200\n",
    "\n",
    "# stepsize α_n\n",
    "def alpha_schedule(n, alpha0=0.5, power=0.6):\n",
    "    return alpha0 / (n ** power)\n",
    "\n",
    "# ------------------------- Helpers -------------------------\n",
    "\n",
    "def coerce_vec(x, J):\n",
    "    if x is None: return np.zeros(J, dtype=float)\n",
    "    a = np.asarray(x, dtype=float).reshape(-1)\n",
    "    if a.size == J: return a\n",
    "    if a.size == 1: return np.full(J, float(a[0]), dtype=float)\n",
    "    return np.zeros(J, dtype=float)\n",
    "\n",
    "def coerce_scalar(x):\n",
    "    if x is None: return 0.0\n",
    "    arr = np.asarray(x, dtype=float).reshape(-1)\n",
    "    return float(arr.mean()) if arr.size else 0.0\n",
    "\n",
    "def eval_vbar_linear(a_list, b_list, t_next, x_post):\n",
    "    \"\"\"V̄_{t+1}(x_post) = a_{t+1}^T x_post + b_{t+1}; t_next is 0-based.\"\"\"\n",
    "    a = np.asarray(a_list[t_next+1], dtype=float).reshape(-1)\n",
    "    b = float(b_list[t_next+1])\n",
    "    return float(a @ np.asarray(x_post, float).reshape(-1) + b)\n",
    "\n",
    "# ------------------------- Stage solvers -------------------------\n",
    "\n",
    "def solve_stage_uc_mip(\n",
    "    t, l_t, u_prev, rho_t, nu_t, R, l_min, l_max, pi_min, pi_max,\n",
    "    a_next, b_next, gen_coeff, lambda_startup,\n",
    "    penalty_scale=1e6, silent=True\n",
    "):\n",
    "    \"\"\"\n",
    "    UC MIP stage with startup costs and soft bounds:\n",
    "      max  sum_j rho_t * g_j * pi_j  + a_{t+1}^T l_{t+1} + b_{t+1}\n",
    "           - sum_j λ_j * ν_j  - penalty\n",
    "      s.t. l_{t+1} = l_t + nu_t + R*pi\n",
    "           u binaries, startup binaries ν with:\n",
    "                ν >= u - u_prev,  ν <= u,  ν <= 1 - u_prev\n",
    "           u * pi_min <= pi <= u * pi_max\n",
    "           soft bounds on l_{t+1}\n",
    "    Returns:\n",
    "      obj, pi*, l_next*, theta_est, x_post, revenue, penalty, startup_cost, u*\n",
    "    \"\"\"\n",
    "    J = l_t.size\n",
    "\n",
    "    with gp.Model(f\"uc_mip_t{t}\") as m:\n",
    "        if silent:\n",
    "            m.Params.OutputFlag = 0\n",
    "        m.Params.Threads = 1\n",
    "\n",
    "        pi    = m.addVars(J, lb=0.0, ub=[float(pi_max[j]) for j in range(J)], name=\"pi\")\n",
    "        u     = m.addVars(J, vtype=GRB.BINARY, name=\"u\")\n",
    "        nuBin = m.addVars(J, vtype=GRB.BINARY, name=\"nu_start\")\n",
    "        lnext = m.addVars(J, lb=-GRB.INFINITY, name=\"l_next\")\n",
    "        s_lo  = m.addVars(J, lb=0.0, name=\"s_lo\")\n",
    "        s_hi  = m.addVars(J, lb=0.0, name=\"s_hi\")\n",
    "\n",
    "        # balance\n",
    "        for j in range(J):\n",
    "            expr = lnext[j] - (float(l_t[j]) + float(nu_t[j]))\n",
    "            expr -= quicksum(float(R[j, k]) * pi[k] for k in range(J))\n",
    "            m.addConstr(expr == 0.0, name=f\"bal_{j}\")\n",
    "\n",
    "        # soft bounds\n",
    "        for j in range(J):\n",
    "            m.addConstr(lnext[j] + s_lo[j] >= float(l_min[j]), name=f\"lb_{j}\")\n",
    "            m.addConstr(lnext[j] - s_hi[j] <= float(l_max[j]), name=f\"ub_{j}\")\n",
    "\n",
    "        # commitment bounds\n",
    "        for j in range(J):\n",
    "            m.addConstr(pi[j] >= float(pi_min[j]) * u[j], name=f\"minflow_{j}\")\n",
    "            m.addConstr(pi[j] <= float(pi_max[j]) * u[j], name=f\"maxflow_{j}\")\n",
    "\n",
    "        # startup logic with u_prev\n",
    "        for j in range(J):\n",
    "            up = float(u_prev[j])\n",
    "            m.addConstr(nuBin[j] >= u[j] - up, name=f\"start_ge_{j}\")\n",
    "            m.addConstr(nuBin[j] <= u[j],      name=f\"start_cap1_{j}\")\n",
    "            m.addConstr(nuBin[j] <= 1.0 - up,  name=f\"start_cap2_{j}\")\n",
    "\n",
    "        # objective\n",
    "        rev  = quicksum(float(rho_t) * float(gen_coeff[j]) * pi[j] for j in range(J))\n",
    "        fut  = quicksum(float(a_next[j]) * lnext[j] for j in range(J)) + float(b_next)\n",
    "        su   = quicksum(float(lambda_startup[j]) * nuBin[j] for j in range(J))\n",
    "        pen  = penalty_scale * (quicksum(s_lo[j] for j in range(J)) + quicksum(s_hi[j] for j in range(J)))\n",
    "        m.setObjective(rev + fut - su - pen, GRB.MAXIMIZE)\n",
    "\n",
    "        m.optimize()\n",
    "        if m.Status not in (GRB.OPTIMAL, GRB.SUBOPTIMAL):\n",
    "            raise RuntimeError(f\"UC MIP infeasible/unbounded at t={t} (status {m.Status})\")\n",
    "\n",
    "        pi_sol = np.array([pi[j].X for j in range(J)], dtype=float)\n",
    "        ln_sol = np.array([lnext[j].X for j in range(J)], dtype=float)\n",
    "        u_sol  = np.array([u[j].X  for j in range(J)], dtype=float)\n",
    "        nu_sol = np.array([nuBin[j].X for j in range(J)], dtype=float)\n",
    "        theta_est = float(np.dot(a_next, ln_sol) + b_next)\n",
    "        x_post = l_t + R.dot(pi_sol)\n",
    "\n",
    "        revenue = float(rho_t) * float(np.dot(gen_coeff, pi_sol))\n",
    "        penalty = penalty_scale * float(sum(s_lo[j].X + s_hi[j].X for j in range(J)))\n",
    "        startup_cost = float(np.dot(lambda_startup, nu_sol))\n",
    "        obj_val = float(m.ObjVal)\n",
    "\n",
    "        # round u to 0/1\n",
    "        u_sol = (u_sol > 0.5).astype(float)\n",
    "\n",
    "        return obj_val, pi_sol, ln_sol, theta_est, x_post, revenue, penalty, startup_cost, u_sol\n",
    "\n",
    "def solve_stage_uc_duals_lp(\n",
    "    t, l_t, u_prev, rho_t, nu_t, R, l_min, l_max, pi_min, pi_max,\n",
    "    a_next, b_next, gen_coeff, lambda_startup, u_fixed,\n",
    "    penalty_scale=1e6, silent=True\n",
    "):\n",
    "    \"\"\"\n",
    "    LP pass with u fixed to u_fixed to get duals on mass-balance constraints.\n",
    "    Startup constraints honored with u_prev and u_fixed; startup cost included.\n",
    "    Returns: lam (dual vector on balance constraints), lp_obj (optional).\n",
    "    \"\"\"\n",
    "    J = l_t.size\n",
    "    with gp.Model(f\"uc_duals_lp_t{t}\") as m:\n",
    "        if silent:\n",
    "            m.Params.OutputFlag = 0\n",
    "        m.Params.Threads = 1\n",
    "\n",
    "        pi    = m.addVars(J, lb=0.0, ub=[float(pi_max[j]) for j in range(J)], name=\"pi\")\n",
    "        lnext = m.addVars(J, lb=-GRB.INFINITY, name=\"l_next\")\n",
    "        s_lo  = m.addVars(J, lb=0.0, name=\"s_lo\")\n",
    "        s_hi  = m.addVars(J, lb=0.0, name=\"s_hi\")\n",
    "        nuBin = m.addVars(J, lb=0.0, ub=1.0, name=\"nu_start_relaxed\")  # continuous [0,1] is fine for LP\n",
    "\n",
    "        # balance + dual capture\n",
    "        bal = []\n",
    "        for j in range(J):\n",
    "            expr = lnext[j] - (float(l_t[j]) + float(nu_t[j]))\n",
    "            expr -= quicksum(float(R[j, k]) * pi[k] for k in range(J))\n",
    "            c = m.addConstr(expr == 0.0, name=f\"bal_{j}\")\n",
    "            bal.append(c)\n",
    "\n",
    "        # soft bounds\n",
    "        for j in range(J):\n",
    "            m.addConstr(lnext[j] + s_lo[j] >= float(l_min[j]), name=f\"lb_{j}\")\n",
    "            m.addConstr(lnext[j] - s_hi[j] <= float(l_max[j]), name=f\"ub_{j}\")\n",
    "\n",
    "        # commitment bounds with u fixed\n",
    "        for j in range(J):\n",
    "            uj = float(u_fixed[j])\n",
    "            m.addConstr(pi[j] >= float(pi_min[j]) * uj, name=f\"minflow_fix_{j}\")\n",
    "            m.addConstr(pi[j] <= float(pi_max[j]) * uj, name=f\"maxflow_fix_{j}\")\n",
    "\n",
    "        # startup constraints with u_prev, u_fixed\n",
    "        for j in range(J):\n",
    "            up = float(u_prev[j]); uj = float(u_fixed[j])\n",
    "            m.addConstr(nuBin[j] >= uj - up, name=f\"start_ge_fix_{j}\")\n",
    "            m.addConstr(nuBin[j] <= uj,      name=f\"start_cap1_fix_{j}\")\n",
    "            m.addConstr(nuBin[j] <= 1.0 - up,name=f\"start_cap2_fix_{j}\")\n",
    "\n",
    "        # objective\n",
    "        rev  = quicksum(float(rho_t) * float(gen_coeff[j]) * pi[j] for j in range(J))\n",
    "        fut  = quicksum(float(a_next[j]) * lnext[j] for j in range(J)) + float(b_next)\n",
    "        su   = quicksum(float(lambda_startup[j]) * nuBin[j] for j in range(J))\n",
    "        pen  = penalty_scale * (quicksum(s_lo[j] for j in range(J)) + quicksum(s_hi[j] for j in range(J)))\n",
    "        m.setObjective(rev + fut - su - pen, GRB.MAXIMIZE)\n",
    "\n",
    "        m.optimize()\n",
    "        if m.Status not in (GRB.OPTIMAL, GRB.SUBOPTIMAL):\n",
    "            raise RuntimeError(f\"UC LP (fixed u) infeasible/unbounded at t={t} (status {m.Status})\")\n",
    "\n",
    "        lam = np.array([c.Pi for c in bal], dtype=float)\n",
    "        return lam, float(m.ObjVal)\n",
    "\n",
    "# ------------------------- Policy evaluation (UC) -------------------------\n",
    "\n",
    "def evaluate_policy_uc(a_t, b_t, l0, prices, inflow, R, l_min, l_max, pi_min, pi_max, g, lambda_startup, gamma=1.0):\n",
    "    \"\"\"Roll out given (a_t, b_t) with UC MIP stage solver over provided paths (with startups).\"\"\"\n",
    "    N_paths, T, J = prices.shape\n",
    "    totals = np.zeros(N_paths, dtype=float)\n",
    "    first_theta = np.zeros(N_paths, dtype=float)\n",
    "\n",
    "    for m in range(N_paths):\n",
    "        l_curr = l0.copy()\n",
    "        u_prev = np.zeros(J, dtype=float)  # assume all-off initially; change if you have a known u0\n",
    "        acc = 0.0\n",
    "        got_first = False\n",
    "        for t in range(T):\n",
    "            obj, pi_next, l_next, theta, x_post, revenue, penalty, startup_cost, u_star = solve_stage_uc_mip(\n",
    "                t=t, l_t=l_curr, u_prev=u_prev, rho_t=float(prices[m, t, 0]),\n",
    "                nu_t=inflow[m, t, :], R=R, l_min=l_min, l_max=l_max,\n",
    "                pi_min=pi_min, pi_max=pi_max, a_next=a_t[t+1], b_next=b_t[t+1],\n",
    "                gen_coeff=g, lambda_startup=lambda_startup, penalty_scale=1e6, silent=True\n",
    "            )\n",
    "            if not got_first:\n",
    "                first_theta[m] = theta\n",
    "                got_first = True\n",
    "            acc += (gamma ** t) * obj\n",
    "            l_curr = l_next\n",
    "            u_prev = u_star  # carry commitment forward\n",
    "        totals[m] = acc\n",
    "\n",
    "    return pd.DataFrame({\"path_id\": np.arange(N_paths), \"total_profit\": totals, \"first_hour_theta\": first_theta})\n",
    "\n",
    "# ------------------------- Main runner -------------------------\n",
    "\n",
    "def run_uc_like_adp_with_duals(\n",
    "    N,\n",
    "    max_iters=MAX_ITERS,\n",
    "    gamma=GAMMA,\n",
    "    seed_train=SEED_TRAIN,\n",
    "    out_prefix=OUT_PREFIX\n",
    "):\n",
    "    t0 = time.time()\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "    # --- generate scenarios (your 16-tuple) ---\n",
    "    (J, T, l_max, l_min, l0, pi_max, pi_min,\n",
    "     price_samples, inflow_samples, nu0, rho0, R,\n",
    "     a_t0, b_t0, l_bar0, alpha_energy) = generate_input(N)\n",
    "\n",
    "    # Shapes/dtypes\n",
    "    l_min = np.asarray(l_min, dtype=np.float32)\n",
    "    l_max = np.asarray(l_max, dtype=np.float32)\n",
    "    l0    = np.asarray(l0,    dtype=np.float32)\n",
    "    pi_min= np.asarray(pi_min,dtype=np.float32)\n",
    "    pi_max= np.asarray(pi_max,dtype=np.float32)\n",
    "    R     = np.asarray(R,     dtype=np.float32)\n",
    "    g     = np.asarray(alpha_energy, dtype=np.float32)\n",
    "\n",
    "    prices = np.asarray(price_samples, dtype=np.float32)  # (N,T)\n",
    "    inflow = np.asarray(inflow_samples, dtype=np.float32) # (N,T,J)\n",
    "    prices = np.repeat(prices[:, :, None], J, axis=2)     # (N,T,J) same price per unit\n",
    "\n",
    "    # Startup costs vector\n",
    "    if STARTUP_COSTS is None:\n",
    "        lambda_startup = np.zeros(J, dtype=np.float32)           # <- change if you want nonzero by default\n",
    "    else:\n",
    "        ls = np.asarray(STARTUP_COSTS, dtype=np.float32).reshape(-1)\n",
    "        if ls.size == 1:\n",
    "            lambda_startup = np.full(J, float(ls[0]), dtype=np.float32)\n",
    "        elif ls.size >= J:\n",
    "            lambda_startup = ls[:J].astype(np.float32)\n",
    "        else:\n",
    "            lambda_startup = np.pad(ls, (0, J-ls.size), constant_values=ls[-1]).astype(np.float32)\n",
    "\n",
    "    # --- split 80/20 like ADP script ---\n",
    "    N_total = N\n",
    "    N_train = int(0.8 * N_total)\n",
    "    N_test  = N_total - N_train\n",
    "\n",
    "    idx = np.arange(N_total)\n",
    "    rng_state = np.random.get_state()\n",
    "    np.random.seed(seed_train)\n",
    "    np.random.shuffle(idx)\n",
    "    np.random.set_state(rng_state)\n",
    "\n",
    "    id_train = idx[:N_train]\n",
    "    id_test  = idx[N_train:]\n",
    "\n",
    "    prices_train = prices[id_train]\n",
    "    inflow_train = inflow[id_train]\n",
    "    prices_test  = prices[id_test]\n",
    "    inflow_test  = inflow[id_test]\n",
    "\n",
    "    # --- initialize a_t, b_t from generator (coerced), length T+1 ---\n",
    "    a_t = [np.zeros(J, dtype=np.float32) for _ in range(T+1)]\n",
    "    b_t = [0.0 for _ in range(T+1)]\n",
    "    if isinstance(a_t0, (list, tuple)):\n",
    "        for t in range(min(T+1, len(a_t0))):\n",
    "            a_t[t] = coerce_vec(a_t0[t], J).astype(np.float32)\n",
    "    if isinstance(b_t0, (list, tuple)):\n",
    "        for t in range(min(T+1, len(b_t0))):\n",
    "            b_t[t] = coerce_scalar(b_t0[t])\n",
    "\n",
    "    # --- logs (same keys as ADP script) ---\n",
    "    history = {\"iter\": [], \"avg_forward_value\": [], \"cum_abs_delta\": []}\n",
    "    perstage_rows = []  # last-iteration per-stage logs\n",
    "    cum_abs = 0.0\n",
    "\n",
    "    # ------------------------ training iterations (MIP + LP for duals) ------------------------\n",
    "    for it in range(1, max_iters + 1):\n",
    "        an = alpha_schedule(it)\n",
    "\n",
    "        # accumulators for Algorithm-6-style updates\n",
    "        sum_omega  = np.zeros((T, J), dtype=np.float64)\n",
    "        sum_adjust = np.zeros(T, dtype=np.float64)\n",
    "\n",
    "        path_totals = np.zeros(N_train, dtype=np.float64)\n",
    "\n",
    "        for m in range(N_train):\n",
    "            l_curr = l0.copy()\n",
    "            u_prev = np.zeros(J, dtype=float)  # assume all-off initially; change if you know u0\n",
    "            for t in range(T):\n",
    "                rho_t = float(prices_train[m, t, 0])\n",
    "                nu_t  = inflow_train[m, t, :]\n",
    "\n",
    "                # 1) UC MIP forward pass (with startup costs)\n",
    "                (obj, pi_next, l_next, theta, x_post, revenue,\n",
    "                 penalty, startup_cost, u_star) = solve_stage_uc_mip(\n",
    "                    t=t, l_t=l_curr, u_prev=u_prev, rho_t=rho_t, nu_t=nu_t, R=R,\n",
    "                    l_min=l_min, l_max=l_max, pi_min=pi_min, pi_max=pi_max,\n",
    "                    a_next=a_t[t+1], b_next=b_t[t+1], gen_coeff=g,\n",
    "                    lambda_startup=lambda_startup, penalty_scale=1e6, silent=True\n",
    "                )\n",
    "\n",
    "                # 2) LP pass for duals with u fixed = u_star (and startup constraints respected)\n",
    "                lam, _ = solve_stage_uc_duals_lp(\n",
    "                    t=t, l_t=l_curr, u_prev=u_prev, rho_t=rho_t, nu_t=nu_t, R=R,\n",
    "                    l_min=l_min, l_max=l_max, pi_min=pi_min, pi_max=pi_max,\n",
    "                    a_next=a_t[t+1], b_next=b_t[t+1], gen_coeff=g,\n",
    "                    lambda_startup=lambda_startup, u_fixed=u_star, penalty_scale=1e6, silent=True\n",
    "                )\n",
    "\n",
    "                # Algorithm-6 averages:\n",
    "                sum_omega[t, :] += lam\n",
    "                sum_adjust[t]   += (obj - float(lam @ l_curr))\n",
    "\n",
    "                # discounted accumulation (forward value)\n",
    "                path_totals[m] += (gamma ** t) * obj\n",
    "\n",
    "                # last-iteration per-stage logging (capped)\n",
    "                if (not LOG_LAST_ITER_ONLY) or (it == MAX_ITERS):\n",
    "                    if m < LOG_MAX_PATHS:\n",
    "                        perstage_rows.append({\n",
    "                            \"N\": N, \"iter\": it, \"path_id\": m, \"t\": t,\n",
    "                            \"obj\": obj, \"theta\": theta\n",
    "                        })\n",
    "\n",
    "                l_curr = l_next\n",
    "                u_prev = u_star  # carry commitment forward\n",
    "\n",
    "        avg_forward = float(np.mean(path_totals))\n",
    "        if it == 1:\n",
    "            cum_abs += 0.0\n",
    "        else:\n",
    "            cum_abs += abs(avg_forward - history[\"avg_forward_value\"][-1])\n",
    "\n",
    "        history[\"iter\"].append(it)\n",
    "        history[\"avg_forward_value\"].append(avg_forward)\n",
    "        history[\"cum_abs_delta\"].append(cum_abs)\n",
    "\n",
    "        # 3) Update a_t,b_t with averages across training paths (backward style)\n",
    "        omega_bar  = (sum_omega / max(N_train, 1)).astype(np.float32)\n",
    "        adjust_bar = (sum_adjust / max(N_train, 1)).astype(np.float32)\n",
    "        for t in range(T-1, -1, -1):\n",
    "            a_t[t] = (1.0 - an) * a_t[t] + an * omega_bar[t, :]\n",
    "            b_t[t] = (1.0 - an) * b_t[t] + an * float(adjust_bar[t])\n",
    "\n",
    "        print(f\"  Iter {it:02d}: avg forward value = {avg_forward:,.3f} (cumΔ={cum_abs:,.3f})\")\n",
    "\n",
    "    # ------------------------ save training logs ------------------------\n",
    "    df_hist = pd.DataFrame(history)\n",
    "    df_hist[\"N\"] = N\n",
    "    df_hist.to_csv(os.path.join(OUTPUT_DIR, f\"{OUT_PREFIX}_history_N{N}.csv\"), index=False)\n",
    "\n",
    "    df_train_perstage = pd.DataFrame(perstage_rows)\n",
    "    df_train_perstage.to_csv(os.path.join(OUTPUT_DIR, f\"{OUT_PREFIX}_train_perstage_N{N}.csv\"), index=False)\n",
    "\n",
    "    # ------------------------ evaluation ------------------------\n",
    "    df_eval_train = evaluate_policy_uc(a_t, b_t, l0, prices_train, inflow_train,\n",
    "                                       R, l_min, l_max, pi_min, pi_max, g, lambda_startup, gamma=GAMMA)\n",
    "    df_eval_train.to_csv(os.path.join(OUTPUT_DIR, f\"{OUT_PREFIX}_train_eval_perpath_N{N}.csv\"), index=False)\n",
    "\n",
    "    df_eval_test = evaluate_policy_uc(a_t, b_t, l0, prices_test, inflow_test,\n",
    "                                      R, l_min, l_max, pi_min, pi_max, g, lambda_startup, gamma=GAMMA)\n",
    "    df_eval_test.to_csv(os.path.join(OUTPUT_DIR, f\"{OUT_PREFIX}_test_eval_perpath_N{N}.csv\"), index=False)\n",
    "\n",
    "    # stats\n",
    "    in_mean  = float(df_eval_train[\"total_profit\"].mean()) if not df_eval_train.empty else 0.0\n",
    "    in_std   = float(df_eval_train[\"total_profit\"].std(ddof=1)) if len(df_eval_train) > 1 else 0.0\n",
    "    test_mean= float(df_eval_test[\"total_profit\"].mean()) if not df_eval_test.empty else 0.0\n",
    "    test_std = float(df_eval_test[\"total_profit\"].std(ddof=1)) if len(df_eval_test) > 1 else 0.0\n",
    "\n",
    "    first_mean = float(df_eval_train[\"first_hour_theta\"].mean()) if not df_eval_train.empty else 0.0\n",
    "    first_std  = float(df_eval_train[\"first_hour_theta\"].std(ddof=1)) if len(df_eval_train) > 1 else 0.0\n",
    "\n",
    "    # ------------------------ save cuts & summary ------------------------\n",
    "    rows = []\n",
    "    for t in range(T+1):\n",
    "        row = {\"stage\": t, \"N\": N, \"b\": float(b_t[t])}\n",
    "        for j in range(J):\n",
    "            row[f\"a_{j}\"] = float(a_t[t][j])\n",
    "        rows.append(row)\n",
    "    pd.DataFrame(rows).to_csv(os.path.join(OUTPUT_DIR, f\"{OUT_PREFIX}_cuts_N{N}.csv\"), index=False)\n",
    "\n",
    "    runtime_sec = time.time() - t0\n",
    "    df_sum = pd.DataFrame([{\n",
    "        \"N\": N,\n",
    "        \"train_size\": N_train, \"test_size\": N_test, \"iters\": MAX_ITERS,\n",
    "        \"runtime_sec\": runtime_sec,\n",
    "        \"final_avg_forward_value\": history[\"avg_forward_value\"][-1],\n",
    "        \"cum_abs_delta\": history[\"cum_abs_delta\"][-1],\n",
    "        \"in_sample_mean\": in_mean, \"in_sample_std\": in_std,\n",
    "        \"test_mean\": test_mean, \"test_std\": test_std,\n",
    "        \"first_hour_theta_mean\": first_mean, \"first_hour_theta_std\": first_std\n",
    "    }])\n",
    "\n",
    "    return ({\"a\": a_t, \"b\": b_t}, {\"history\": df_hist}, df_sum)\n",
    "\n",
    "# ------------------------- Driver -------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "    all_summaries = []\n",
    "    N = None\n",
    "\n",
    "    if N is None:\n",
    "        for N in range(100, 1001, 100):  # 100, 200, ..., 1000\n",
    "            print(f\"\\n=== Running UC Algorithm-6 (MIP+LP duals, with startups) with N={N} samples ===\")\n",
    "            _, _, df_sum = run_uc_like_adp_with_duals(\n",
    "                N=N, max_iters=MAX_ITERS, gamma=GAMMA,\n",
    "                seed_train=SEED_TRAIN, out_prefix=OUT_PREFIX\n",
    "            )\n",
    "            all_summaries.append(df_sum)\n",
    "    else:\n",
    "        print(f\"\\n=== Running UC Algorithm-6 (MIP+LP duals, with startups) with N={N} samples ===\")\n",
    "        _, _, df_sum = run_uc_like_adp_with_duals(\n",
    "            N=N, max_iters=MAX_ITERS, gamma=GAMMA,\n",
    "            seed_train=SEED_TRAIN, out_prefix=OUT_PREFIX\n",
    "        )\n",
    "        all_summaries.append(df_sum)\n",
    "\n",
    "    df_all = pd.concat(all_summaries, ignore_index=True)\n",
    "    df_all.to_csv(os.path.join(OUTPUT_DIR, f\"{OUT_PREFIX}_summary_allN.csv\"), index=False)\n",
    "    print(\"\\nDone. Summaries written to\", os.path.abspath(OUTPUT_DIR))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
